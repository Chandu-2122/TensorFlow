{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chandu-2122/TensorFlow/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RFTYVBSVQg_"
      },
      "source": [
        "The main goal of natural language processing (NLP) is to derive information from natural language(sequence to sequence problems) like:\n",
        "\n",
        "Text (such as that contained in an email, blog post, book, Tweet)\n",
        "\n",
        "Speech (a conversation you have with a doctor, voice commands you give to a smart speaker)\n",
        "\n",
        "NLP process:\n",
        "\n",
        "Downloading a text dataset\n",
        "\n",
        "Visualizing text data\n",
        "\n",
        "Converting text into numbers using tokenization\n",
        "\n",
        "Turning our tokenized text into an embedding\n",
        "\n",
        "Modelling a text dataset\n",
        "\n",
        "Starting with a baseline (TF-IDF)\n",
        "\n",
        "Building several deep learning text models\n",
        "\n",
        "Dense, LSTM, GRU, Conv1D, Transfer learning\n",
        "\n",
        "Comparing the performance of each our models\n",
        "\n",
        "Combining our models into an ensemble\n",
        "\n",
        "Saving and loading a trained model\n",
        "\n",
        "Find the most wrong predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urXrQ9IgaW73"
      },
      "source": [
        "#Checking for GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGcnxj1ORc27",
        "outputId": "74d8056f-4049-453b-df75-250758f90957"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-4ca352d3-94f9-606b-7fc3-a2113762a0b8)\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLV7q-GEaxxV"
      },
      "source": [
        "#Getting helper functions\n",
        "\n",
        "The script containing our helper functions to do small tasks can be found on GitHub."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2gy1jUaaeRG",
        "outputId": "9c1f2eeb-4457-4015-9ebb-a6e2d9f39b93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-19 17:34:58--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-12-19 17:34:59 (98.4 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#downloading helper functions\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8_TJcKyNbi5m"
      },
      "outputs": [],
      "source": [
        "# Import series of helper functions for the notebook\n",
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRYhNhHxeF2Q"
      },
      "source": [
        "#Downloading the text dataset\n",
        "\n",
        "We will be using Real or Not? dataset from kaggle which contains text-based Tweets about natural disasters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ml8c5hJYbvIz",
        "outputId": "49256635-cab4-4ad5-c1ed-817238edcfdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-19 17:35:02--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.183.128, 173.194.193.128, 173.194.194.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.183.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2022-12-19 17:35:02 (98.7 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#download data same as from kaggle\n",
        "!wget \"https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\"\n",
        "\n",
        "# Unzip data\n",
        "unzip_data(\"nlp_getting_started.zip\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21SFap6tf_T1"
      },
      "source": [
        "Unzipping nlp_getting_started.zip gives the following 3 .csv files:\n",
        "\n",
        "sample_submission.csv - an example of the file you'd submit to the Kaggle competition of your model's predictions.\n",
        "\n",
        "train.csv - training samples of real and not real diaster Tweets.\n",
        "\n",
        "test.csv - testing samples of real and not real diaster Tweets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aePl2qVOgN9U"
      },
      "source": [
        "#Visualizing the dataset\n",
        "\n",
        "Let's convert our .csv files into pandas dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zf8PcWu3pNrv",
        "outputId": "fe60b372-8701-4fd3-bd9e-2641528abb58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access 'nlp_getting_started': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!ls nlp_getting_started"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rO6aaksjf50y",
        "outputId": "f215047c-b017-4040-fc13-ba22b3384398"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id keyword location  \\\n",
              "7608  10869     NaN      NaN   \n",
              "7609  10870     NaN      NaN   \n",
              "7610  10871     NaN      NaN   \n",
              "7611  10872     NaN      NaN   \n",
              "7612  10873     NaN      NaN   \n",
              "\n",
              "                                                   text  target  \n",
              "7608  Two giant cranes holding a bridge collapse int...       1  \n",
              "7609  @aria_ahrary @TheTawniest The out of control w...       1  \n",
              "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n",
              "7611  Police investigating after an e-bike collided ...       1  \n",
              "7612  The Latest: More Homes Razed by Northern Calif...       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6a847423-f142-4684-9060-e7614d104b40\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7608</th>\n",
              "      <td>10869</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7609</th>\n",
              "      <td>10870</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7610</th>\n",
              "      <td>10871</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7611</th>\n",
              "      <td>10872</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Police investigating after an e-bike collided ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7612</th>\n",
              "      <td>10873</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a847423-f142-4684-9060-e7614d104b40')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6a847423-f142-4684-9060-e7614d104b40 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6a847423-f142-4684-9060-e7614d104b40');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "train_df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xTeCMQYnuJMN",
        "outputId": "185230df-cc47-4aba-a08c-9ac11e813488"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id      keyword                   location  \\\n",
              "1461  2109  catastrophe                        NaN   \n",
              "1462  2110  catastrophe    Wellington, New Zealand   \n",
              "1463  2111  catastrophe         West Virginia, USA   \n",
              "1464  2112  catastrophe                        NaN   \n",
              "1465  2113  catastrophe                      ?? ??   \n",
              "1466  2114  catastrophe                        NaN   \n",
              "1467  2115  catastrophe                    Florida   \n",
              "1468  2116  catastrophe                        NaN   \n",
              "1469  2117  catastrophe                        NaN   \n",
              "1470  2118  catastrophe                        NaN   \n",
              "1471  2119  catastrophe            los angeles, ca   \n",
              "1472  2121  catastrophe                        NaN   \n",
              "1473  2122  catastrophe          New Brunswick, NJ   \n",
              "1474  2123  catastrophe         City of Angels, CA   \n",
              "1475  2125  catastrophe               Brooklyn, NY   \n",
              "1476  2126  catastrophe        Morganville, Texas.   \n",
              "1477  2128  catastrophe     America | New Zealand    \n",
              "1478  2129  catastrophe                        NaN   \n",
              "1479  2131  catastrophe                        NaN   \n",
              "1480  2133  catastrophe                 Denver, CO   \n",
              "1481  2134  catastrophe                        NaN   \n",
              "1482  2136  catastrophe                        NaN   \n",
              "1483  2138  catastrophe          Stockholm, Sweden   \n",
              "1484  2139  catastrophe                  Worldwide   \n",
              "1485  2141  catastrophe                    Azeroth   \n",
              "1486  2142  catastrophe          Lytham St Anne's    \n",
              "1487  2144  catastrophe                        NaN   \n",
              "1488  2145  catastrophe                        NaN   \n",
              "1489  2146  catastrophe                     Ylisse   \n",
              "1490  2148  catastrophe                  Wisconsin   \n",
              "1491  2149  catastrophe                   Portugal   \n",
              "1492  2150  catastrophe  All around the world baby   \n",
              "1493  2153  catastrophe                        NaN   \n",
              "1494  2154  catastrophe                        NaN   \n",
              "1495  2157  catastrophe   @UntmdOutdoors #T.O.R.K    \n",
              "1496  2158  catastrophe                Lima, PerÌ¼   \n",
              "\n",
              "                                                   text  target  \n",
              "1461  .@robdelaney  Catastrophe is anything but! I l...       1  \n",
              "1462  @APPLEOFFIClAL Migrating from iPhoto to Photo ...       0  \n",
              "1463  Cultivating Joy In The Face Of Catastrophe And...       0  \n",
              "1464  #Borrowers concerned at possible #interest rat...       0  \n",
              "1465  .@uriminzok The coming catastrophe of the dest...       0  \n",
              "1466  failure is a misfortunebut regret is a catastr...       0  \n",
              "1467  @deb117 7/30 that catastrophe man opens school...       0  \n",
              "1468  #iphone #twist Ultimate #preparedness library:...       0  \n",
              "1469  @gemmahentsch @megynkelly @DLoesch I can not e...       0  \n",
              "1470  @peterjukes But there are good grounds to beli...       1  \n",
              "1471  Then the stylist who'd been silent says 'there...       0  \n",
              "1472  #boy #mix Ultimate #preparedness library: http...       1  \n",
              "1473                              God bless catastrophe       0  \n",
              "1474  @MaatMHI Slightly diff catastrophe &amp; Barry...       0  \n",
              "1475  UPDATE: 7 of the 9 Mac Pros my company bought ...       1  \n",
              "1476  Pisces tweets need to get better because most ...       0  \n",
              "1477  Taylor and Cara aka Catastrophe and Mother Chu...       0  \n",
              "1478  [reviews] #PixelsMovie not a catastrophe nor a...       0  \n",
              "1479  Burford. What a catastrophe! Traffic and big l...       0  \n",
              "1480  #Denver CO #Insurance #Job: Claims Property Fi...       0  \n",
              "1481  #spark #song Ultimate #preparedness library: h...       0  \n",
              "1482  12 Month Payday Short Catastrophe Loans - Prom...       0  \n",
              "1483  I rated Catastrophe (2015) 8/10  #IMDb - hilar...       0  \n",
              "1484  .@AIGinsurance CEO: Divestitures and #Catastro...       0  \n",
              "1485  Chances are many of us are still digging out f...       1  \n",
              "1486  Oh my god thatÛªs the biggest #gbbo catastrop...       0  \n",
              "1487  #nar #phuket Ultimate #preparedness library: h...       1  \n",
              "1488  not a catastrophe at all I'm perfectly content...       0  \n",
              "1489  @MasochisticMage + catastrophe! It caused peop...       0  \n",
              "1490  I had 2 regular coffees and a Rockstar + coffe...       0  \n",
              "1491  Alaska's #Wolves face catastrophe Denali Wolve...       0  \n",
              "1492  @mark_argent I haven't watched that one yet. J...       0  \n",
              "1493  bbc r5live studio discussion of hiroshima v po...       1  \n",
              "1494  Human history becomes more and more a race bet...       0  \n",
              "1495  Success is not built on success. Its built on ...       0  \n",
              "1496  Britney Spears &gt; Vegas!! I missed you so mu...       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a2b7cb53-0d75-45b8-b962-2d7d0b1ba201\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1461</th>\n",
              "      <td>2109</td>\n",
              "      <td>catastrophe</td>\n",
              "      <td>NaN</td>\n",
              "      <td>.@robdelaney  Catastrophe is anything but! I l...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1462</th>\n",
              "      <td>2110</td>\n",
              "      <td>catastrophe</td>\n",
              "      <td>Wellington, New Zealand</td>\n",
              "      <td>@APPLEOFFIClAL Migrating from iPhoto to Photo ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1463</th>\n",
              "      <td>2111</td>\n",
              "      <td>catastrophe</td>\n",
              "      <td>West Virginia, USA</td>\n",
              "      <td>Cultivating Joy In The Face Of Catastrophe And...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1464</th>\n",
              "      <td>2112</td>\n",
              "      <td>catastrophe</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#Borrowers concerned at possible #interest rat...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1465</th>\n",
              "      <td>2113</td>\n",
              "      <td>catastrophe</td>\n",
              "      <td>?? ??</td>\n",
              "      <td>.@uriminzok The coming catastrophe of the dest...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1466</th>\n",
              "      <td>2114</td>\n",
              "      <td>catastrophe</td>\n",
              "      <td>NaN</td>\n",
              "      <td>failure is a misfortunebut regret is a catastr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1467</th>\n",
              "      <td>2115</td>\n",
              "      <td>catastrophe</td>\n",
              "      <td>Florida</td>\n",
              "      <td>@deb117 7/30 that catastrophe man opens school...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1468</th>\n",
              "      <td>2116</td>\n",
              "      <td>catastrophe</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#iphone #twist Ultimate #preparedness library:...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1469</th>\n",
              "      <td>2117</td>\n",
              "      <td>catastrophe</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@gemmahentsch @megynkelly @DLoesch I can not e...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1470</th>\n",
              "      <td>2118</td>\n",
              "      <td>catastrophe</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@peterjukes But there are good grounds to beli...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1471</th>\n",
              "      <td>2119</td>\n",
              "      <td>catastrophe</td>\n",
              "      <td>los angeles, ca</td>\n",
              "      <td>Then the stylist who'd been silent says 'there...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1472</th>\n",
              "      <td>2121</td>\n",
              "      <td>catastrophe</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#boy #mix Ultimate #preparedness library: http...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1473</th>\n",
              "      <td>2122</td>\n",
              "      <td>catastrophe</td>\n",
              "      <td>New Brunswick, NJ</td>\n",
              "      <td>God bless catastrophe</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1474</th>\n",
              "      <td>2123</td>\n",
              "      <td>catastrophe</td>\n",
              "      <td>City of Angels, CA</td>\n",
              "      <td>@MaatMHI Slightly diff catastrophe &amp;amp; Barry...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1475</th>\n",
              "      <td>2125</td>\n",
              "      <td>catastrophe</td>\n",
              "      <td>Brooklyn, NY</td>\n",
              "      <td>UPDATE: 7 of the 9 Mac Pros my company bought ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1476</th>\n",
              "      <td>2126</td>\n",
              "      <td>catastrophe</td>\n",
              "      <td>Morganville, Texas.</td>\n",
              "      <td>Pisces tweets need to get better because most ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1477</th>\n",
              "      <td>2128</td>\n",
              "      <td>catastrophe</td>\n",
              "      <td>America | New Zealand</td>\n",
              "      <td>Taylor and Cara aka Catastrophe and Mother Chu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1478</th>\n",
              "      <td>2129</td>\n",
              "      <td>catastrophe</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[reviews] #PixelsMovie not a catastrophe nor a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1479</th>\n",
              "      <td>2131</td>\n",
              "      <td>catastrophe</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Burford. What a catastrophe! Traffic and big l...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1480</th>\n",
              "      <td>2133</td>\n",
              "      <td>catastrophe</td>\n",
              "      <td>Denver, CO</td>\n",
              "      <td>#Denver CO #Insurance #Job: Claims Property Fi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1481</th>\n",
              "      <td>2134</td>\n",
              "      <td>catastrophe</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#spark #song Ultimate #preparedness library: h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1482</th>\n",
              "      <td>2136</td>\n",
              "      <td>catastrophe</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12 Month Payday Short Catastrophe Loans - Prom...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1483</th>\n",
              "      <td>2138</td>\n",
              "      <td>catastrophe</td>\n",
              "      <td>Stockholm, Sweden</td>\n",
              "      <td>I rated Catastrophe (2015) 8/10  #IMDb - hilar...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1484</th>\n",
              "      <td>2139</td>\n",
              "      <td>catastrophe</td>\n",
              "      <td>Worldwide</td>\n",
              "      <td>.@AIGinsurance CEO: Divestitures and #Catastro...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1485</th>\n",
              "      <td>2141</td>\n",
              "      <td>catastrophe</td>\n",
              "      <td>Azeroth</td>\n",
              "      <td>Chances are many of us are still digging out f...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1486</th>\n",
              "      <td>2142</td>\n",
              "      <td>catastrophe</td>\n",
              "      <td>Lytham St Anne's</td>\n",
              "      <td>Oh my god thatÛªs the biggest #gbbo catastrop...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1487</th>\n",
              "      <td>2144</td>\n",
              "      <td>catastrophe</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#nar #phuket Ultimate #preparedness library: h...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1488</th>\n",
              "      <td>2145</td>\n",
              "      <td>catastrophe</td>\n",
              "      <td>NaN</td>\n",
              "      <td>not a catastrophe at all I'm perfectly content...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1489</th>\n",
              "      <td>2146</td>\n",
              "      <td>catastrophe</td>\n",
              "      <td>Ylisse</td>\n",
              "      <td>@MasochisticMage + catastrophe! It caused peop...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1490</th>\n",
              "      <td>2148</td>\n",
              "      <td>catastrophe</td>\n",
              "      <td>Wisconsin</td>\n",
              "      <td>I had 2 regular coffees and a Rockstar + coffe...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1491</th>\n",
              "      <td>2149</td>\n",
              "      <td>catastrophe</td>\n",
              "      <td>Portugal</td>\n",
              "      <td>Alaska's #Wolves face catastrophe Denali Wolve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1492</th>\n",
              "      <td>2150</td>\n",
              "      <td>catastrophe</td>\n",
              "      <td>All around the world baby</td>\n",
              "      <td>@mark_argent I haven't watched that one yet. J...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1493</th>\n",
              "      <td>2153</td>\n",
              "      <td>catastrophe</td>\n",
              "      <td>NaN</td>\n",
              "      <td>bbc r5live studio discussion of hiroshima v po...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1494</th>\n",
              "      <td>2154</td>\n",
              "      <td>catastrophe</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Human history becomes more and more a race bet...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1495</th>\n",
              "      <td>2157</td>\n",
              "      <td>catastrophe</td>\n",
              "      <td>@UntmdOutdoors #T.O.R.K</td>\n",
              "      <td>Success is not built on success. Its built on ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1496</th>\n",
              "      <td>2158</td>\n",
              "      <td>catastrophe</td>\n",
              "      <td>Lima, PerÌ¼</td>\n",
              "      <td>Britney Spears &amp;gt; Vegas!! I missed you so mu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a2b7cb53-0d75-45b8-b962-2d7d0b1ba201')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a2b7cb53-0d75-45b8-b962-2d7d0b1ba201 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a2b7cb53-0d75-45b8-b962-2d7d0b1ba201');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "train_df[train_df[\"keyword\"]==\"catastrophe\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "00eQ8iX8qxJo",
        "outputId": "d87661b2-ef20-4e90-d32c-8bedb616ed78"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id            keyword location  \\\n",
              "1467  2115        catastrophe  Florida   \n",
              "6453  9232  suicide%20bombing      NaN   \n",
              "5698  8131            rescued  Ireland   \n",
              "5769  8236               riot  Seattle   \n",
              "6853  9822             trauma      NaN   \n",
              "\n",
              "                                                   text  target  \n",
              "1467  @deb117 7/30 that catastrophe man opens school...       0  \n",
              "6453  meek mill should join isis since he loves suic...       0  \n",
              "5698  Three beached whales rescued in Kerry - http:/...       1  \n",
              "5769  Southeast Dirt Riot Series Crowns Champions:  ...       0  \n",
              "6853  Hiroshima: They told me to paint my story: Eig...       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-25735b8b-49c9-49b7-b5e4-93160318cf09\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1467</th>\n",
              "      <td>2115</td>\n",
              "      <td>catastrophe</td>\n",
              "      <td>Florida</td>\n",
              "      <td>@deb117 7/30 that catastrophe man opens school...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6453</th>\n",
              "      <td>9232</td>\n",
              "      <td>suicide%20bombing</td>\n",
              "      <td>NaN</td>\n",
              "      <td>meek mill should join isis since he loves suic...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5698</th>\n",
              "      <td>8131</td>\n",
              "      <td>rescued</td>\n",
              "      <td>Ireland</td>\n",
              "      <td>Three beached whales rescued in Kerry - http:/...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5769</th>\n",
              "      <td>8236</td>\n",
              "      <td>riot</td>\n",
              "      <td>Seattle</td>\n",
              "      <td>Southeast Dirt Riot Series Crowns Champions:  ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6853</th>\n",
              "      <td>9822</td>\n",
              "      <td>trauma</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Hiroshima: They told me to paint my story: Eig...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-25735b8b-49c9-49b7-b5e4-93160318cf09')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-25735b8b-49c9-49b7-b5e4-93160318cf09 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-25735b8b-49c9-49b7-b5e4-93160318cf09');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "#shuffling the data\n",
        "train_df_shuffled = train_df.sample(frac=1, random_state=22) \n",
        "#shuffle with random_state=22 for reproducibility\n",
        "train_df_shuffled.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVRoWbU2t8iT",
        "outputId": "096f358e-e33d-4c43-f57e-d1f26f77e8d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column names in training dataset: ['id', 'keyword', 'location', 'text', 'target']\n",
            "Column names in testing dataset: Index(['id', 'keyword', 'location', 'text'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "#Let's view the column names in both test and training dataset\n",
        "print(\"Column names in training dataset:\", list(train_df.columns))\n",
        "print(\"Column names in testing dataset:\", test_df.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gm-_GBpAyWCC"
      },
      "source": [
        "We can see that there is no 'target' column in the testing data.\n",
        "\n",
        "So, we are going to be writing the code to find patterns of different combinations of words in the 'text' column of the training dataset to predict the values of the 'target' column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThIJYK6FyRf1",
        "outputId": "50f18671-e7df-47b7-ae98-f5b12d87f474"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "#let's see how many are there in each type of target\n",
        "train_df.target.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWSTYVduzzaI"
      },
      "source": [
        "We can see that we will be dealing with binary classification:\n",
        "\n",
        "1 = a real disaster Tweet\n",
        "\n",
        "0 = not a real disaster Tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kRLkFcwzkSl",
        "outputId": "7e03d4be-38db-44b4-ae41-c05b89e06ba1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total training samples: 7613\n",
            "total test samples: 3263\n",
            "total samples: 10876\n"
          ]
        }
      ],
      "source": [
        "#let's view the total no.of samples we have\n",
        "print(f\"total training samples: {len(train_df)}\")\n",
        "print(\"total test samples:\", len(test_df))\n",
        "print(\"total samples:\", len(train_df)+len(test_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lW5AihOY0YrX",
        "outputId": "2cf3efc4-65d3-45ff-a2f6-a7a1b635ee7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "Ari's hints and snippets will be the death of me.\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "Time collapse is such a cool video technique.  https://t.co/upLFSqMr0C\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "I understand you wanting to hang out with your guy friends I'll give you your space but don't ruin my trust with you.\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "A Look at State Actions a Year After #Ferguson's Upheaval http://t.co/qwSbVfLPE1\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "News@ Refugio oil spill may have been costlier bigger than projected http://t.co/jhpdSSVhvE\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Let's visualize some random training examples\n",
        "import random\n",
        "random_index = random.randint(0, len(train_df)-5) # create random indexes not higher than the total number of samples\n",
        "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
        "  _, text, target = row #_ gets rid of the index value \n",
        "  print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"---\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "9ZGcq-xPAcMv",
        "outputId": "e914dfb3-aaec-4c4c-8621-b789985f32e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "train_df_shuffled[\"text\"][2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImdSZg9Fugys"
      },
      "source": [
        "#Splitting into training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "trA7-uJcAied"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use train_test_split to split training data into training and validation sets\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(), #array\n",
        "                                                                            train_df_shuffled[\"target\"].to_numpy(),\n",
        "                                                                            test_size=0.1, # dedicate 10% of samples to validation set\n",
        "                                                                            random_state=22) # random state for reproducibility\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYmYtH_kvShw",
        "outputId": "120a4b4f-3ac4-455b-c043-144ceda69522"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([\"RT @GreenHarvard: Documenting climate change's first major casualty http://t.co/4q4zd7oU34 via @GreenHarvard\",\n",
              "        '#Colorado #News Motorcyclist bicyclist injured in Denver collision on Broadway: At least two people were tak... http://t.co/2iAFPmqJeP',\n",
              "        \"Wreckage 'Conclusively Confirmed' as From MH370: Malaysia PM: Investigators and the families of those who were... http://t.co/VAZpG0ftmU\",\n",
              "        'HURRICANE GUILLERMO LIVE NOAA TRACKING / LOOPING WED.AUG.5TH ~ http://t.co/RjopJKbydR ~  http://t.co/NUFDgw9YEv http://t.co/2oKSCwYoHC',\n",
              "        '@morehouse64 It appears our #Govt has lost an #Ethical and or moral relevance. This means the whole #USA population is in danger from them.'],\n",
              "       dtype=object), array([1, 1, 1, 1, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "train_sentences[:5], train_labels[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtXocv5dvXri",
        "outputId": "34ec97bf-8388-4224-f95d-179407c3c2d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 6851)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "#checking the lengths\n",
        "len(train_sentences), len(train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnT2RCRqva9j",
        "outputId": "58338515-47d6-4136-c8f0-538976460c41"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(762, 762)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "len(val_sentences), len(val_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-S28yoIV8Cp"
      },
      "source": [
        "#Converting text into numbers\n",
        "\n",
        "A machine learning algorithm requires its inputs to be in numerical form.\n",
        "\n",
        "Tokenization: converting each word/character(token) to a number.\n",
        "\n",
        "Types:word level tokenization, character level tokenization, sub word tokenization\n",
        "\n",
        "Embedding: every word/character gets converted into a feature vector matrix.(representation of relationships between tokens). use embeddings by creating your own or reusing a pre learned embedding from TensorflowHub.\n",
        "\n",
        "The process of each sample contains the following steps:\n",
        "\n",
        "1. Standardize each sample(usually lowercasing + punctuation stripping)\n",
        "\n",
        "2. Split each sample into substrings(usually words)\n",
        "\n",
        "3. recombine substrings into tokens(usually ngrams-no.of words per split)\n",
        "\n",
        "4. index tokens (associate a unique int value with each token)\n",
        "\n",
        "5. transform each sample using this index, either into a vector of ints or a dense float vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "1ncJ_xBhVT5E"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "#we can also use: tf.keras.layers.TextVectorization\n",
        "\n",
        "#using the default parameters\n",
        "text_vectorizer = TextVectorization(max_tokens = None, #max no.of words in the vocabulary, includes a value for OOV (out of vocabulary))\n",
        "                                    standardize = \"lower_and_strip_punctuation\", # lowers text and removes all punctuation marks.\n",
        "                                    split = \"whitespace\", #splits on spaces.\n",
        "                                    ngrams = None,  #creates groups of n words\n",
        "                                    output_mode = \"int\", #way of outputting the tokens\n",
        "                                    output_sequence_length = None, #Length of tokenized sequence to output.\n",
        "                                    pad_to_max_tokens = False) #if true, the output feature axis will be padded to max_tokens even if the number of unique tokens in the vocabulary is less than max_tokens. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NU5UCxEqi0Sb",
        "outputId": "8c3110c7-9ac6-448b-eced-e963a663dc2b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "len(train_sentences[0].split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SR3dyGXJpqG",
        "outputId": "5807b303-1012-42d5-fcb7-f2e12b655569"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6851"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "len(train_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyusPfJ-et4X",
        "outputId": "ffa6f531-3755-4efc-a024-fd71bfe3c060"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "#finding the average no.of tokens(words) in the training tweets.\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Ge7c9qadjLKO"
      },
      "outputs": [],
      "source": [
        " #setting up text vectorization variables\n",
        "\n",
        " max_vocab_length = 10000 #max no.of words to have in our vocabulary\n",
        " max_length = 15 #max length of sequences from the tweet\n",
        "\n",
        " text_vectorizer = TextVectorization(max_tokens = max_vocab_length,\n",
        "                                     output_mode = \"int\",\n",
        "                                     output_sequence_length = max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "C2XAAuFbixo1"
      },
      "outputs": [],
      "source": [
        "#fitting the text vectorizer to the training set\n",
        "\n",
        "text_vectorizer.adapt(train_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xf94TppJQMVu",
        "outputId": "863222aa-519a-44d7-cf5e-6d33f2db136d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[1665,  105,   63,   21,   12,    8,  233,   16,   12,   21,  609,\n",
              "         238,    0,    0,    0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "#viewing the text vectorizer on a custom sentence\n",
        "sample_sentence = \"Hi world! How are you? I hope that you are doing well.\"\n",
        "text_vectorizer([sample_sentence])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7TFhGHIRij1"
      },
      "source": [
        " the 0's at the end of the returned tensor, is because we set output_sequence_length=15, meaning no matter the size of the sequence we pass to text_vectorizer, it always returns a sequence with a length of 15."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDfip7AVQyQv",
        "outputId": "fca05fa5-4788-4a86-b4e3-f17e4cfbd260"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the original text is:\n",
            " @Bloodbath_TV favourite YouTube channel going right now.\n",
            "Love everything you guys do and thank you introducing me to Dude Bro Party Massacre \n",
            " vectorized version is:\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[   1, 5660,  112, 3109,   99,  166,   49,  114,  736,   12,  570,\n",
              "          70,    7,  529,   12]])>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "#let's check it on a random sentence from the train sentences\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(\"the original text is:\\n\", random_sentence, \"\\n vectorized version is:\\n\")\n",
        "text_vectorizer([random_sentence])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pHODCoDSBVw",
        "outputId": "b014ac2b-cd5a-49ac-b97b-d8092c1d8306"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocab: 10000\n",
            "Top 5 most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
            "Bottom 5 least common words: ['paramedics', 'paraguay', 'paradise', 'parade', 'paracord']\n"
          ]
        }
      ],
      "source": [
        "#let's check the unique tokens in our vocabulary using the get_vocabulary() method.\n",
        "\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "top_5_words = words_in_vocab[:5] # most common tokens (notice the [UNK] token for \"unknown\" words)\n",
        "bottom_5_words = words_in_vocab[-5:] # least common tokens\n",
        "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
        "print(f\"Top 5 most common words: {top_5_words}\") \n",
        "print(f\"Bottom 5 least common words: {bottom_5_words}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7_d_Byca5sI"
      },
      "source": [
        "#converting numbers into embedding\n",
        "\n",
        "parameters:\n",
        "input_dim - The size of the vocabulary (e.g. len(text_vectorizer.get_vocabulary()).\n",
        "\n",
        "output_dim - The size of the output embedding vector, for example, a value of 100 outputs a feature vector of size 100 for each word.\n",
        "\n",
        "embeddings_initializer - How to initialize the embeddings matrix, default is \"uniform\" which randomly initalizes embedding matrix with uniform distribution. This can be changed for using pre-learned embeddings.\n",
        "\n",
        "input_length - Length of sequences being passed to embedding layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "i7JpoYQrTz-V"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim = max_vocab_length,#set input shape\n",
        "                             output_dim = 128, #output shape\n",
        "                             embeddings_initializer=\"uniform\", # default, intialize randomly\n",
        "                             input_length = max_length) #how long is each input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PePJOKSAcQQH",
        "outputId": "e6761669-a00f-43d2-bd30-d4ed6f38a46c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.core.embedding.Embedding at 0x7f40e05e14c0>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCd6JfpfcxGv",
        "outputId": "e8bd66a2-37ee-41af-d2f1-4e0e9052d3cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the original text is:\n",
            " Mane im not a Raiders Fan but they been in a drought. They need to go 10-6 lol \n",
            "\n",
            "embedded version is:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[ 0.02164792,  0.04774182, -0.04527951, ...,  0.00869552,\n",
              "         -0.0373032 , -0.02466962],\n",
              "        [-0.02719255,  0.01207029,  0.036036  , ...,  0.04501344,\n",
              "         -0.03858986, -0.02483296],\n",
              "        [ 0.00298379,  0.04796869,  0.02805969, ..., -0.02636375,\n",
              "         -0.00165633, -0.03877025],\n",
              "        ...,\n",
              "        [ 0.02665985, -0.01045359, -0.02996025, ...,  0.03828548,\n",
              "          0.01882255,  0.0366508 ],\n",
              "        [-0.02736924,  0.01189058, -0.03555019, ..., -0.01171125,\n",
              "          0.03394112, -0.01662649],\n",
              "        [-0.03340498, -0.04968831,  0.00810909, ..., -0.00851904,\n",
              "         -0.00931442, -0.04951819]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "#let's check it on a random sentence from the train sentences\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(\"the original text is:\\n\", random_sentence, \"\\n\\nembedded version is:\")\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzCO_93cfEXO"
      },
      "source": [
        "Each token in the sentence gets turned into a length 128 feature vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCbBID9DdIzN",
        "outputId": "725deb4a-7163-4bd4-da48-2d4f96c5671e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              " array([ 0.02164792,  0.04774182, -0.04527951,  0.02838815,  0.01125596,\n",
              "         0.02479983, -0.04617891,  0.03581801,  0.03179494,  0.03803447,\n",
              "        -0.04721824,  0.03731574, -0.02196716, -0.02876793, -0.04887008,\n",
              "         0.03509918,  0.02780633,  0.00962629, -0.04524333,  0.04420277,\n",
              "         0.0228083 ,  0.04561993, -0.00832061,  0.02665016, -0.01961532,\n",
              "        -0.02400054,  0.01837398,  0.00894254, -0.01563298, -0.00117116,\n",
              "         0.02211699, -0.02849853,  0.00333997, -0.04977211, -0.00393164,\n",
              "        -0.0322148 , -0.01847662, -0.00630359,  0.04624735, -0.00901405,\n",
              "        -0.00043578,  0.00981579, -0.03834005,  0.01418683, -0.003747  ,\n",
              "        -0.02352403, -0.03185107,  0.01799432,  0.04852087, -0.03127639,\n",
              "        -0.01694226, -0.03297921, -0.03597121,  0.00105195, -0.04744241,\n",
              "        -0.02870601,  0.00622137,  0.03245505, -0.01004994,  0.04629212,\n",
              "         0.03698541, -0.0166343 ,  0.03400762, -0.03601416,  0.04392501,\n",
              "         0.0308114 , -0.04117088, -0.04876641, -0.03532051,  0.00521268,\n",
              "         0.00194918, -0.0384347 , -0.00715152,  0.04156195,  0.01261045,\n",
              "        -0.03265788, -0.01144651,  0.00697551, -0.03815806, -0.04530919,\n",
              "         0.01202927,  0.00238508,  0.00818008,  0.02786123, -0.03009949,\n",
              "         0.02719269,  0.03123492,  0.00484295,  0.02022395,  0.03729094,\n",
              "        -0.00089974, -0.02856669, -0.00812139, -0.02412562, -0.04291273,\n",
              "         0.00391299,  0.04941747,  0.011689  ,  0.00822767, -0.0203414 ,\n",
              "         0.0386256 ,  0.03041938, -0.0023052 , -0.0380923 , -0.00370642,\n",
              "         0.00253408,  0.00848887,  0.04168749, -0.02304351, -0.03868849,\n",
              "         0.0031747 ,  0.01182145, -0.01898274,  0.0175049 ,  0.03662933,\n",
              "        -0.04456614,  0.03135986, -0.00975478, -0.04152007,  0.00758189,\n",
              "         0.00881797,  0.04945425,  0.04625065, -0.01396976, -0.01255144,\n",
              "         0.00869552, -0.0373032 , -0.02466962], dtype=float32)>,\n",
              " TensorShape([128]),\n",
              " 'Mane im not a Raiders Fan but they been in a drought. They need to go 10-6 lol')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "#checking out a single token's embedding\n",
        "sample_embed[0][0], sample_embed[0][0].shape, random_sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-s-fucRJgk3Q"
      },
      "source": [
        "#Modelling a text dataset\n",
        "\n",
        "Since the data is converted into numbers, we can start to build the machine learning models now.\n",
        "\n",
        "We will be building the following models and compare the results to know which performed best:\n",
        "\n",
        "Model 0: Naive Bayes(baseline, simplest)-set of probabilistic classifiers that aim to process, analyze, and categorize data.\n",
        "\n",
        "Model 1: Feed-forward neural network (dense model)-connections between nodes does not form a cycle. The opposite of a feed forward neural network is a recurrent neural network, in which certain pathways are cycled. \n",
        "\n",
        "Model 2: LSTM model-enables the network to remember inputs information for a longer period of time.(has input, output and forget gates)\n",
        "\n",
        "Model 3: GRU model-can be trained to keep information from the past(update gate) or remove information that is irrelevant to the prediction(reset gate). Fixes vanishing gradient problem \n",
        "\n",
        "Model 4: Bidirectional-LSTM model-consists of two LSTMs: one taking the input in a forward direction, and the other in a backwards direction.\n",
        "\n",
        "Model 5: 1D Convolutional Neural Network-using multiple copies of the same neuron in different places.\n",
        "\n",
        "Model 6: TensorFlow Hub Pretrained Feature Extractor\n",
        "\n",
        "Model 7: Same as model 6 with 10% of training data\n",
        "\n",
        "Each experiment will go through the following steps:\n",
        "\n",
        "Construct the model\n",
        "\n",
        "Train the model\n",
        "\n",
        "Make predictions with the model\n",
        "\n",
        "Track prediction evaluation metrics for later comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "px0W5yPilsn_"
      },
      "source": [
        "#Model 0: Getting a baseline model\n",
        "\n",
        "To create our baseline, we'll create a Scikit-Learn Pipeline using the TF-IDF (term frequency-inverse document frequency) formula to convert our words to numbers and then model them with the Multinomial Naive Bayes algorithm.\n",
        "\n",
        "TfidfVectorizer()-Term Frequency Inverse Document Frequency: This function helps us to convert the text into vectors by counting the number of times each word appeared in a document.\n",
        "\n",
        "TF-IDF value of a term = TF x IDF\n",
        "\n",
        "Term frequency(TF) = (Number of times term 't' appears in a document)/(Number of terms in the document)\n",
        "\n",
        "Inverse Document Frequency(IDF) = log(N/n), where, 'N' is the number of documents and 'n' is the number of documents a term 't' has appeared in.\n",
        "\n",
        "The IDF value of a rare word is high, whereas the IDF of a frequent word is low.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBzYRbfdfNcF",
        "outputId": "675590e7-09f6-49e8-b36e-b888fbddd5ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "#create tokenization and modelling pipeline\n",
        "model_0 = Pipeline([  #building steps in order just like keras sequential model\n",
        "                    (\"tfidf\", TfidfVectorizer()),  #converting text into numbers\n",
        "                    (\"clf\", MultinomialNB())  #model the text    \n",
        "])\n",
        "\n",
        "#fit the pipeline to the training data\n",
        "model_0.fit(train_sentences, train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pL-f_bQTtG49",
        "outputId": "fddaf37e-915a-4d21-bdce-ecaa13c06715"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score of baseline model: 83.33333333333334\n"
          ]
        }
      ],
      "source": [
        "#Evaluating our baseline model\n",
        "baseline_score = model_0.score(val_sentences, val_labels)\n",
        "print(\"Accuracy score of baseline model:\",baseline_score*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbUWn7AbuTgw",
        "outputId": "a12d70f4-da4a-4875-8592-bb9cecb75f4f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 1, 0, 0, 1, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "#making predictions with baseline model\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:10] #predicted output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDzJTMu5w-Sp",
        "outputId": "cab9bcb5-3ec1-4119-bbbc-8760d654e0e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 1, 0, 0, 0, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "val_labels[:10] #actual output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf3DZaeJxW_v"
      },
      "source": [
        "#Creating an evaluation function for our model experiments\n",
        "\n",
        "let's create a helper function which takes an array of predictions and ground truth labels for every model and computes the following:\n",
        "\n",
        "Accuracy\n",
        "\n",
        "Precision\n",
        "\n",
        "Recall\n",
        "\n",
        "F1-score\n",
        "\n",
        "One of the parameter in precision_recall_fscore_support:\n",
        "\n",
        "average{‘binary’, ‘micro’, ‘macro’, ‘samples’, ‘weighted’}, default=None\n",
        "\n",
        "If None, the scores for each class are returned. Otherwise, this determines the type of averaging performed on the data:\n",
        "\n",
        "'binary':\n",
        "Only report results for the class specified by pos_label. This is applicable only if targets (y_{true,pred}) are binary.\n",
        "\n",
        "'micro':\n",
        "Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
        "\n",
        "'macro':\n",
        "Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account.\n",
        "\n",
        "'weighted':\n",
        "Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label). This alters ‘macro’ to account for label imbalance; it can result in an F-score that is not between precision and recall.\n",
        "\n",
        "'samples':\n",
        "Calculate metrics for each instance, and find their average (only meaningful for multilabel classification where this differs from accuracy_score)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "w4o2OwXIxCmO"
      },
      "outputs": [],
      "source": [
        "#function to evaluate: accuracy, precision, recall, f1 score\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "\n",
        "  Args:\n",
        "  -----\n",
        "  y_true = true labels in the form of a 1D array\n",
        "  y_pred = predicted labels in the form of a 1D array\n",
        "\n",
        "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
        "  \"\"\"\n",
        "\n",
        "  #calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred)*100\n",
        "\n",
        "  #calculate model precision, recall and f1 score using \"weighted\" average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                   \"precision\": model_precision,  #precision is the ratio tp / (tp + fp)\n",
        "                   \"recall\": model_recall,  #recall is the ratio tp / (tp + fn)\n",
        "                   \"f1\": model_f1} #weighted harmonic mean of the precision and recall, \n",
        "                   #where an F-beta score reaches its best value at 1 and worst score at 0.}\n",
        "\n",
        "  return model_results\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZlBPuE_z4VM",
        "outputId": "4d09584c-f438-4aa6-cb5e-66f3416234db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 83.33333333333334,\n",
              " 'precision': 0.8412202657738648,\n",
              " 'recall': 0.8333333333333334,\n",
              " 'f1': 0.8293755882702342}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "#let's view the baseline results from the function we created\n",
        "\n",
        "baseline_results = calculate_results(y_true=val_labels,\n",
        "                                     y_pred=baseline_preds)\n",
        "baseline_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMkndP6i36qT"
      },
      "source": [
        "#Model_1: A simple dense model\n",
        "\n",
        "It is a single layer dense model.\n",
        "\n",
        "It'll take our text and labels as input, tokenize the text, create an embedding, find the average of the embedding (using Global Average Pooling) and then pass the average through a fully connected layer with one output unit and a sigmoid activation function.\n",
        "\n",
        "since we're going to be building a number of TensorFlow deep learning models, we'll import our create_tensorboard_callback() function from helper_functions.py to keep track of the results of each."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "G4tDMotT0Rw3"
      },
      "outputs": [],
      "source": [
        "# Create tensorboard callback (need to create a new one for each model)\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "# Create directory to save TensorBoard logs\n",
        "SAVE_DIR = \"model_logs\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "yQikuS7m5DMH"
      },
      "outputs": [],
      "source": [
        "# Build model with the Functional API\n",
        "from tensorflow.keras import layers\n",
        "# inputs are 1-dimensional strings\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\") \n",
        "# turn the input text into numbers\n",
        "x = text_vectorizer(inputs) \n",
        "# create an embedding of the numerized numbers\n",
        "x = embedding(x) \n",
        "# lower the dimensionality of the embedding (try running the model without this layer and see what happens)\n",
        "x = layers.GlobalAveragePooling1D()(x) \n",
        "# create the output layer, want binary outputs so use sigmoid activation\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x) \n",
        "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\") # construct the model\n",
        "\n",
        "\n",
        "      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wg96UMpUGtv3",
        "outputId": "0d4c8e03-327e-4638-e72c-f5b39fe2155d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "0hpH-tVMHTXi"
      },
      "outputs": [],
      "source": [
        "model_1.compile(loss = \"binary_crossentropy\",\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = [\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4T9M6uP5J4n6",
        "outputId": "5a86e3a0-4739-452f-c9ea-d4d448a965da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/simple_dense_model/20221219-173507\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 4s 6ms/step - loss: 0.6127 - accuracy: 0.6898 - val_loss: 0.5085 - val_accuracy: 0.8202\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.4458 - accuracy: 0.8133 - val_loss: 0.4316 - val_accuracy: 0.8202\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.3503 - accuracy: 0.8591 - val_loss: 0.4193 - val_accuracy: 0.8386\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.2871 - accuracy: 0.8905 - val_loss: 0.4253 - val_accuracy: 0.8333\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.2387 - accuracy: 0.9099 - val_loss: 0.4468 - val_accuracy: 0.8228\n"
          ]
        }
      ],
      "source": [
        "# Fit the model\n",
        "model_1_history = model_1.fit(train_sentences, # input sentences can be a list of strings due to text preprocessing layer built-in model\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR, \n",
        "                                                                     experiment_name=\"simple_dense_model\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rY32nPhBJ90V",
        "outputId": "d967bc3e-dd87-4873-91e2-25c8c0a32466"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4468 - accuracy: 0.8228\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4467511475086212, 0.8228346705436707]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "model_1.evaluate(val_sentences, val_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mc6BU62yxpr",
        "outputId": "d51b00b2-738b-410d-e04f-ffe4462becb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(762, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "#making some predictions and evaluating them\n",
        "model_1_pred_probs = model_1.predict(val_sentences)\n",
        "model_1_pred_probs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNfdhUegzG_d",
        "outputId": "9c3bc5a9-4ceb-432a-9f0e-79f5b1075152"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.99833727],\n",
              "       [0.09818594],\n",
              "       [0.10597119],\n",
              "       [0.8963544 ],\n",
              "       [0.00155129],\n",
              "       [0.38279074],\n",
              "       [0.8609975 ],\n",
              "       [0.23097064],\n",
              "       [0.58906406],\n",
              "       [0.12506503]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "model_1_pred_probs[:10] #predicted values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMQdcqDtzW7B",
        "outputId": "556bd00b-2544-4d3d-9d09-49e2bc4b2c90"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 1, 0, 0, 0, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "val_labels[:10]  #actual values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwM7gjNN0syg",
        "outputId": "b5866845-7c47-460f-9a41-71b8bcec3d7b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 0., 0., 1., 0., 0., 1., 0., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "#converting the model prediction probability values to the label format\n",
        "#squeeze:Removes dimensions of size 1 from the shape of a tensor.\n",
        "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs))\n",
        "model_1_preds[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekgA0m_a1ZoD",
        "outputId": "95aba73b-006e-4af4-909c-ea7e6914d812"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 0., 0., 1., 0., 0., 1., 0., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "tf.round(model_1_pred_probs)\n",
        "model_1_preds[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dlw4CPPG2Xs0",
        "outputId": "bf90b37b-286d-47dd-fe7d-9585b45a298b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 82.28346456692913,\n",
              " 'precision': 0.8226450757390502,\n",
              " 'recall': 0.8228346456692913,\n",
              " 'f1': 0.8227269262463532}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "#calculating the results of model_1\n",
        "model_1_results = calculate_results(y_true = val_labels, y_pred = model_1_preds)\n",
        "model_1_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgfldT0d6d-B",
        "outputId": "59ff0126-45e7-4ce6-aa6f-6c538d883a60"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 83.33333333333334,\n",
              " 'precision': 0.8412202657738648,\n",
              " 'recall': 0.8333333333333334,\n",
              " 'f1': 0.8293755882702342}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "#comparing to baseline\n",
        "baseline_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Au3Xo80jIk5a"
      },
      "source": [
        "#Visualizing learned embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXJjGNAt6j1-",
        "outputId": "be3ed97e-d9af-4b03-cb4b-279051c4b633"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "#getting the vocabulary from the text vectorization layer\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "len(words_in_vocab), words_in_vocab[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDKYUMrUI2gc",
        "outputId": "a54204cd-292d-42b5-bb07-13c89aa65da5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " 'the',\n",
              " 'a',\n",
              " 'in',\n",
              " 'to',\n",
              " 'of',\n",
              " 'and',\n",
              " 'i',\n",
              " 'is',\n",
              " 'for',\n",
              " 'on',\n",
              " 'you',\n",
              " 'my',\n",
              " 'with',\n",
              " 'it',\n",
              " 'that',\n",
              " 'at',\n",
              " 'by',\n",
              " 'this',\n",
              " 'from',\n",
              " 'are',\n",
              " 'be',\n",
              " 'was',\n",
              " 'have',\n",
              " 'like',\n",
              " 'me',\n",
              " 'up',\n",
              " 'but',\n",
              " 'so',\n",
              " 'just',\n",
              " 'as',\n",
              " 'amp',\n",
              " 'im',\n",
              " 'not',\n",
              " 'your',\n",
              " 'out',\n",
              " 'its',\n",
              " 'after',\n",
              " 'an',\n",
              " 'will',\n",
              " 'all',\n",
              " 'no',\n",
              " 'fire',\n",
              " 'has',\n",
              " 'when',\n",
              " 'if',\n",
              " 'we',\n",
              " 'get',\n",
              " 'now',\n",
              " 'new',\n",
              " 'via',\n",
              " 'more',\n",
              " 'or',\n",
              " 'about',\n",
              " 'they',\n",
              " 'people',\n",
              " 'dont',\n",
              " 'what',\n",
              " 'news',\n",
              " 'he',\n",
              " 'over',\n",
              " 'one',\n",
              " 'how',\n",
              " 'been',\n",
              " 'who',\n",
              " 'into',\n",
              " 'were',\n",
              " 'can',\n",
              " 'video',\n",
              " 'do',\n",
              " 'us',\n",
              " 'emergency',\n",
              " '2',\n",
              " 'disaster',\n",
              " 'than',\n",
              " 'there',\n",
              " 'would',\n",
              " 'police',\n",
              " 'his',\n",
              " 'her',\n",
              " 'still',\n",
              " 'some',\n",
              " 'burning',\n",
              " 'body',\n",
              " 'back',\n",
              " 'off',\n",
              " 'california',\n",
              " 'crash',\n",
              " 'buildings',\n",
              " 'why',\n",
              " 'storm',\n",
              " 'day',\n",
              " 'time',\n",
              " 'know',\n",
              " 'man',\n",
              " 'them',\n",
              " 'suicide',\n",
              " 'rt',\n",
              " 'going',\n",
              " 'had',\n",
              " 'got',\n",
              " 'first',\n",
              " 'see',\n",
              " 'nuclear',\n",
              " 'world',\n",
              " 'two',\n",
              " 'our',\n",
              " 'cant',\n",
              " 'bomb',\n",
              " '3',\n",
              " 'fires',\n",
              " 'youtube',\n",
              " 'attack',\n",
              " 'love',\n",
              " 'go',\n",
              " 'dead',\n",
              " 'being',\n",
              " 'train',\n",
              " 'war',\n",
              " 'car',\n",
              " 'life',\n",
              " 'killed',\n",
              " 'down',\n",
              " 'accident',\n",
              " 'today',\n",
              " 'their',\n",
              " 'may',\n",
              " 'think',\n",
              " 'only',\n",
              " 'families',\n",
              " 'watch',\n",
              " 'hiroshima',\n",
              " 'say',\n",
              " 'full',\n",
              " 'many',\n",
              " 'did',\n",
              " 'could',\n",
              " 'u',\n",
              " 'here',\n",
              " 'good',\n",
              " 'last',\n",
              " 'home',\n",
              " 'years',\n",
              " 'collapse',\n",
              " 'then',\n",
              " 'want',\n",
              " 'too',\n",
              " 'really',\n",
              " 'because',\n",
              " 'work',\n",
              " 'wildfire',\n",
              " 'make',\n",
              " 'look',\n",
              " 'him',\n",
              " 'way',\n",
              " 'mass',\n",
              " 'lol',\n",
              " 'am',\n",
              " 'please',\n",
              " 'take',\n",
              " 'help',\n",
              " 'best',\n",
              " 'need',\n",
              " 'even',\n",
              " 'death',\n",
              " 'right',\n",
              " 'year',\n",
              " 'army',\n",
              " 'another',\n",
              " '4',\n",
              " 'those',\n",
              " 'pm',\n",
              " 'should',\n",
              " 'obama',\n",
              " 'never',\n",
              " 'let',\n",
              " 'legionnaires',\n",
              " 'youre',\n",
              " 'wreck',\n",
              " 'she',\n",
              " 'school',\n",
              " 'northern',\n",
              " 'mh370',\n",
              " 'hot',\n",
              " 'city',\n",
              " 'bombing',\n",
              " '2015',\n",
              " 'water',\n",
              " 'homes',\n",
              " 'fatal',\n",
              " 'black',\n",
              " '1',\n",
              " '\\x89Û',\n",
              " 'forest',\n",
              " 'latest',\n",
              " 'great',\n",
              " 'god',\n",
              " 'fear',\n",
              " 'any',\n",
              " 'thats',\n",
              " 'shit',\n",
              " 'much',\n",
              " 'come',\n",
              " 'under',\n",
              " 'old',\n",
              " '5',\n",
              " 'flood',\n",
              " 'flames',\n",
              " 'every',\n",
              " 'while',\n",
              " 'said',\n",
              " 'live',\n",
              " 'everyone',\n",
              " 'bomber',\n",
              " 'atomic',\n",
              " 'where',\n",
              " 'weather',\n",
              " 'near',\n",
              " 'getting',\n",
              " 'feel',\n",
              " 'ever',\n",
              " 'coming',\n",
              " 'read',\n",
              " 'next',\n",
              " 'floods',\n",
              " 'during',\n",
              " 'ass',\n",
              " 'these',\n",
              " 'severe',\n",
              " 'plan',\n",
              " 'night',\n",
              " 'most',\n",
              " 'hope',\n",
              " 'evacuation',\n",
              " 'earthquake',\n",
              " 'content',\n",
              " 'before',\n",
              " 'well',\n",
              " 'top',\n",
              " 'military',\n",
              " 'injured',\n",
              " 'damage',\n",
              " 'which',\n",
              " 'truck',\n",
              " 'theres',\n",
              " 'set',\n",
              " 'malaysia',\n",
              " 'little',\n",
              " 'japan',\n",
              " 'flooding',\n",
              " 'face',\n",
              " 'wounded',\n",
              " 'without',\n",
              " 'thunderstorm',\n",
              " 'through',\n",
              " 'stop',\n",
              " 's',\n",
              " 'hit',\n",
              " 'found',\n",
              " 'warning',\n",
              " 'since',\n",
              " 'oil',\n",
              " 'looks',\n",
              " 'cross',\n",
              " 'confirmed',\n",
              " 'cause',\n",
              " 'weapons',\n",
              " 'times',\n",
              " 'state',\n",
              " 'smoke',\n",
              " 'heat',\n",
              " 'fucking',\n",
              " 'fall',\n",
              " 'debris',\n",
              " 'check',\n",
              " 'bags',\n",
              " 'sinking',\n",
              " 'movie',\n",
              " 'loud',\n",
              " 'house',\n",
              " 'free',\n",
              " 'food',\n",
              " 'collided',\n",
              " 'bad',\n",
              " 'wild',\n",
              " 'weapon',\n",
              " 'w',\n",
              " 'until',\n",
              " 'thunder',\n",
              " 'says',\n",
              " 'injuries',\n",
              " 'high',\n",
              " 'boy',\n",
              " 'bloody',\n",
              " 'whole',\n",
              " 'save',\n",
              " 'rescue',\n",
              " 'reddit',\n",
              " 'made',\n",
              " 'liked',\n",
              " 'hes',\n",
              " 'failure',\n",
              " 'evacuate',\n",
              " 'blood',\n",
              " 'also',\n",
              " 'again',\n",
              " 'wind',\n",
              " 'terrorist',\n",
              " 'summer',\n",
              " 'sinkhole',\n",
              " 'services',\n",
              " 'screaming',\n",
              " 'run',\n",
              " 'outbreak',\n",
              " 'murder',\n",
              " 'does',\n",
              " 'destroy',\n",
              " 'derailment',\n",
              " 'always',\n",
              " 'air',\n",
              " 'twister',\n",
              " 'survive',\n",
              " 'rain',\n",
              " 'photo',\n",
              " 'natural',\n",
              " 'lightning',\n",
              " 'ive',\n",
              " 'head',\n",
              " 'girl',\n",
              " 'family',\n",
              " 'end',\n",
              " 'change',\n",
              " 'bridge',\n",
              " 'around',\n",
              " 'wrecked',\n",
              " 'trapped',\n",
              " 'structural',\n",
              " 'story',\n",
              " 'sandstorm',\n",
              " 'ruin',\n",
              " 'road',\n",
              " 'refugees',\n",
              " 'migrants',\n",
              " 'hurricane',\n",
              " 'gonna',\n",
              " 'explosion',\n",
              " 'explode',\n",
              " 'deaths',\n",
              " 'call',\n",
              " 'bag',\n",
              " '70',\n",
              " 'wreckage',\n",
              " 'white',\n",
              " 'whirlwind',\n",
              " 'survived',\n",
              " 'spill',\n",
              " 'saw',\n",
              " 'report',\n",
              " 'real',\n",
              " 'injury',\n",
              " 'ill',\n",
              " 'hail',\n",
              " 'fuck',\n",
              " 'dust',\n",
              " 'destruction',\n",
              " 'destroyed',\n",
              " 'cliff',\n",
              " 'bus',\n",
              " 'burned',\n",
              " 'breaking',\n",
              " 'big',\n",
              " 'away',\n",
              " 'attacked',\n",
              " 'armageddon',\n",
              " 'ambulance',\n",
              " '40',\n",
              " 'update',\n",
              " 'tonight',\n",
              " 'someone',\n",
              " 'show',\n",
              " 'riot',\n",
              " 'post',\n",
              " 'phone',\n",
              " 'panic',\n",
              " 'ok',\n",
              " 'missing',\n",
              " 'lives',\n",
              " 'landslide',\n",
              " 'keep',\n",
              " 'hostages',\n",
              " 'hazardous',\n",
              " 'game',\n",
              " 'fatalities',\n",
              " 'derail',\n",
              " 'curfew',\n",
              " 'crashed',\n",
              " 'charged',\n",
              " 'better',\n",
              " 'airplane',\n",
              " 'against',\n",
              " 'woman',\n",
              " 'trauma',\n",
              " 'things',\n",
              " 'thing',\n",
              " 'terrorism',\n",
              " 'rioting',\n",
              " 'rescuers',\n",
              " 'rescued',\n",
              " 'red',\n",
              " 'put',\n",
              " 'power',\n",
              " 'other',\n",
              " 'oh',\n",
              " 'mudslide',\n",
              " 'kills',\n",
              " 'island',\n",
              " 'investigators',\n",
              " 'heard',\n",
              " 'hazard',\n",
              " 'harm',\n",
              " 'electrocuted',\n",
              " 'devastation',\n",
              " 'deluge',\n",
              " 'danger',\n",
              " 'crush',\n",
              " 'came',\n",
              " 'bombed',\n",
              " 'area',\n",
              " 'apocalypse',\n",
              " 'women',\n",
              " 'windstorm',\n",
              " 'week',\n",
              " 'service',\n",
              " 'screamed',\n",
              " 'released',\n",
              " 'quarantine',\n",
              " 'past',\n",
              " 'lava',\n",
              " 'drowning',\n",
              " 'drought',\n",
              " 'displaced',\n",
              " 'catastrophic',\n",
              " 'catastrophe',\n",
              " 'boat',\n",
              " 'august',\n",
              " '15',\n",
              " 'went',\n",
              " 'wave',\n",
              " 'wanna',\n",
              " 'violent',\n",
              " 'very',\n",
              " 'traumatised',\n",
              " 'tragedy',\n",
              " 'traffic',\n",
              " 'suspect',\n",
              " 'survivors',\n",
              " 'sure',\n",
              " 'something',\n",
              " 'saudi',\n",
              " 'quarantined',\n",
              " 'possible',\n",
              " 'part',\n",
              " 'panicking',\n",
              " 'national',\n",
              " 'long',\n",
              " 'least',\n",
              " 'inundated',\n",
              " 'hundreds',\n",
              " 'hostage',\n",
              " 'hijacker',\n",
              " 'heart',\n",
              " 'famine',\n",
              " 'desolation',\n",
              " 'collapsed',\n",
              " 'blown',\n",
              " 'bang',\n",
              " 'affected',\n",
              " 'sunk',\n",
              " 'soon',\n",
              " 'screams',\n",
              " 'razed',\n",
              " 'pandemonium',\n",
              " 'minute',\n",
              " 'massacre',\n",
              " 'lot',\n",
              " 'left',\n",
              " 'horrible',\n",
              " 'group',\n",
              " 'engulfed',\n",
              " 'derailed',\n",
              " 'demolish',\n",
              " 'county',\n",
              " 'collide',\n",
              " 'casualties',\n",
              " 'blew',\n",
              " 'anniversary',\n",
              " 'airport',\n",
              " 'zone',\n",
              " 'yet',\n",
              " 'wounds',\n",
              " 'twitter',\n",
              " 'tsunami',\n",
              " 'trouble',\n",
              " 'stock',\n",
              " 'stay',\n",
              " 'sirens',\n",
              " 'must',\n",
              " 'meltdown',\n",
              " 'land',\n",
              " 'issues',\n",
              " 'isis',\n",
              " 'iran',\n",
              " 'hijacking',\n",
              " 'fedex',\n",
              " 'exploded',\n",
              " 'detonate',\n",
              " 'crushed',\n",
              " 'cool',\n",
              " 'chemical',\n",
              " 'bleeding',\n",
              " 'blast',\n",
              " 'baby',\n",
              " 'annihilated',\n",
              " 'use',\n",
              " 'typhoon',\n",
              " 'tornado',\n",
              " 'tomorrow',\n",
              " 'thought',\n",
              " 'thank',\n",
              " 'send',\n",
              " 'security',\n",
              " 'river',\n",
              " 'responders',\n",
              " 'officer',\n",
              " 'obliteration',\n",
              " 'obliterated',\n",
              " 'obliterate',\n",
              " 'murderer',\n",
              " 'lets',\n",
              " 'id',\n",
              " 'half',\n",
              " 'government',\n",
              " 'goes',\n",
              " 'flattened',\n",
              " 'evacuated',\n",
              " 'electrocute',\n",
              " 'ebay',\n",
              " 'drowned',\n",
              " 'done',\n",
              " 'detonation',\n",
              " 'care',\n",
              " 'bioterror',\n",
              " 'beautiful',\n",
              " '\\x89ÛÒ',\n",
              " 'three',\n",
              " 'thanks',\n",
              " 'shoulder',\n",
              " 'shooting',\n",
              " 'seismic',\n",
              " 'reunion',\n",
              " 'remember',\n",
              " 'plane',\n",
              " 'officials',\n",
              " 'nothing',\n",
              " 'mosque',\n",
              " 'light',\n",
              " 'kill',\n",
              " 'kids',\n",
              " 'india',\n",
              " 'guys',\n",
              " 'fatality',\n",
              " 'due',\n",
              " 'drown',\n",
              " 'didnt',\n",
              " 'demolition',\n",
              " 'demolished',\n",
              " 'collision',\n",
              " 'caused',\n",
              " 'calgary',\n",
              " 'building',\n",
              " 'battle',\n",
              " 'ablaze',\n",
              " '8',\n",
              " 'wait',\n",
              " 'volcano',\n",
              " 'used',\n",
              " 'swallowed',\n",
              " 'sue',\n",
              " 'start',\n",
              " 'st',\n",
              " 'song',\n",
              " 'site',\n",
              " 'prebreak',\n",
              " 'pkk',\n",
              " 'person',\n",
              " 'nearby',\n",
              " 'market',\n",
              " 'making',\n",
              " 'longer',\n",
              " 'leave',\n",
              " 'israeli',\n",
              " 'inside',\n",
              " 'hijack',\n",
              " 'having',\n",
              " 'gets',\n",
              " 'fun',\n",
              " 'far',\n",
              " 'eyewitness',\n",
              " 'doing',\n",
              " 'detonated',\n",
              " 'already',\n",
              " '9',\n",
              " '6',\n",
              " 'yes',\n",
              " 'whats',\n",
              " 'wake',\n",
              " 'ur',\n",
              " 'sound',\n",
              " 'same',\n",
              " 'rainstorm',\n",
              " 'policy',\n",
              " 'plans',\n",
              " 'outside',\n",
              " 'men',\n",
              " 'media',\n",
              " 'hell',\n",
              " 'fan',\n",
              " 'declares',\n",
              " 'days',\n",
              " 'cyclone',\n",
              " 'bush',\n",
              " 'blight',\n",
              " 'blazing',\n",
              " 'arson',\n",
              " 'almost',\n",
              " 'actually',\n",
              " '20',\n",
              " '\\x89ÛÓ',\n",
              " 'yourself',\n",
              " 'words',\n",
              " 'watching',\n",
              " 'turkey',\n",
              " 'support',\n",
              " 'south',\n",
              " 'snowstorm',\n",
              " 'siren',\n",
              " 'play',\n",
              " 'nowplaying',\n",
              " 'north',\n",
              " 'music',\n",
              " 'islam',\n",
              " 'hear',\n",
              " 'health',\n",
              " 'fight',\n",
              " 'few',\n",
              " 'brown',\n",
              " 'both',\n",
              " 'bagging',\n",
              " 'avalanche',\n",
              " 'abc',\n",
              " '7',\n",
              " 'typhoondevastated',\n",
              " 'trying',\n",
              " 'tell',\n",
              " 'stretcher',\n",
              " 'second',\n",
              " 'saipan',\n",
              " 'rubble',\n",
              " 're\\x89Û',\n",
              " 'photos',\n",
              " 'memories',\n",
              " 'lab',\n",
              " 'horror',\n",
              " 'hellfire',\n",
              " 'doesnt',\n",
              " 'died',\n",
              " 'bar',\n",
              " 'american',\n",
              " 'ago',\n",
              " '16yr',\n",
              " 'yeah',\n",
              " 'wont',\n",
              " 'west',\n",
              " 'upheaval',\n",
              " 'tv',\n",
              " 'trains',\n",
              " 'such',\n",
              " 'street',\n",
              " 'searching',\n",
              " 'saved',\n",
              " 'reactor',\n",
              " 'place',\n",
              " 'peace',\n",
              " 'own',\n",
              " 'order',\n",
              " 'n',\n",
              " 'mp',\n",
              " 'move',\n",
              " 'money',\n",
              " 'maybe',\n",
              " 'line',\n",
              " 'hours',\n",
              " 'history',\n",
              " 'helicopter',\n",
              " 'feeling',\n",
              " 'die',\n",
              " 'deluged',\n",
              " 'deal',\n",
              " 'd',\n",
              " 'crews',\n",
              " 'conclusively',\n",
              " 'book',\n",
              " 'bc',\n",
              " 'anything',\n",
              " '30',\n",
              " 'youth',\n",
              " 'waves',\n",
              " 'shot',\n",
              " 'seen',\n",
              " 'reuters',\n",
              " 'pretty',\n",
              " 'pick',\n",
              " 'others',\n",
              " 'online',\n",
              " 'okay',\n",
              " 'myself',\n",
              " 'manslaughter',\n",
              " 'major',\n",
              " 'low',\n",
              " 'literally',\n",
              " 'la',\n",
              " 'huge',\n",
              " 'giant',\n",
              " 'find',\n",
              " 'finally',\n",
              " 'everything',\n",
              " 'desolate',\n",
              " 'data',\n",
              " 'crisis',\n",
              " 'class',\n",
              " 'children',\n",
              " 'child',\n",
              " 'case',\n",
              " 'business',\n",
              " 'anyone',\n",
              " 'annihilation',\n",
              " 'amid',\n",
              " 'aircraft',\n",
              " 'wrong',\n",
              " 'united',\n",
              " 'transport',\n",
              " 'theyre',\n",
              " 't',\n",
              " 'stand',\n",
              " 'soudelor',\n",
              " 'signs',\n",
              " 'side',\n",
              " 'shes',\n",
              " 'rise',\n",
              " 'probably',\n",
              " 'poor',\n",
              " 'pic',\n",
              " 'pakistan',\n",
              " 'omg',\n",
              " 'nearly',\n",
              " 'makes',\n",
              " 'lost',\n",
              " 'lord',\n",
              " 'level',\n",
              " 'hate',\n",
              " 'hard',\n",
              " 'happy',\n",
              " 'eyes',\n",
              " 'east',\n",
              " 'damn',\n",
              " 'daily',\n",
              " 'center',\n",
              " 'caught',\n",
              " 'casualty',\n",
              " 'called',\n",
              " 'bodies',\n",
              " 'bioterrorism',\n",
              " 'bigger',\n",
              " 'bestnaijamade',\n",
              " 'believe',\n",
              " 'across',\n",
              " '50',\n",
              " '12',\n",
              " 'win',\n",
              " 'village',\n",
              " 'usa',\n",
              " 'truth',\n",
              " 'town',\n",
              " 'texas',\n",
              " 'team',\n",
              " 'taken',\n",
              " 'ship',\n",
              " 'russian',\n",
              " 'picking',\n",
              " 'official',\n",
              " 'needs',\n",
              " 'name',\n",
              " 'might',\n",
              " 'm',\n",
              " 'hollywood',\n",
              " 'hey',\n",
              " 'happened',\n",
              " 'hailstorm',\n",
              " 'gbbo',\n",
              " 'fukushima',\n",
              " 'friends',\n",
              " 'flash',\n",
              " 'flag',\n",
              " 'crazy',\n",
              " 'country',\n",
              " 'control',\n",
              " 'closed',\n",
              " 'china',\n",
              " 'cars',\n",
              " 'blaze',\n",
              " 'ball',\n",
              " 'b',\n",
              " 'aug',\n",
              " 'angry',\n",
              " 'america',\n",
              " '11yearold',\n",
              " 'worst',\n",
              " 'womens',\n",
              " 'view',\n",
              " 'trust',\n",
              " 'trench',\n",
              " 'totally',\n",
              " 'till',\n",
              " 'takes',\n",
              " 'spot',\n",
              " 'space',\n",
              " 'self',\n",
              " 'reason',\n",
              " 'rd',\n",
              " 'projected',\n",
              " 'pay',\n",
              " 'pain',\n",
              " 'once',\n",
              " 'offensive',\n",
              " 'mph',\n",
              " 'morning',\n",
              " 'mom',\n",
              " 'miners',\n",
              " 'mayhem',\n",
              " 'looking',\n",
              " 'listen',\n",
              " 'leather',\n",
              " 'learn',\n",
              " 'jobs',\n",
              " 'job',\n",
              " 'issued',\n",
              " 'houses',\n",
              " 'hat',\n",
              " 'global',\n",
              " 'friend',\n",
              " 'feared',\n",
              " 'effect',\n",
              " 'drive',\n",
              " 'disea',\n",
              " 'devastated',\n",
              " 'course',\n",
              " 'climate',\n",
              " 'centre',\n",
              " 'become',\n",
              " 'bbc',\n",
              " 'appears',\n",
              " 'alone',\n",
              " 'aint',\n",
              " 'aftershock',\n",
              " '60',\n",
              " '11',\n",
              " 'wow',\n",
              " 'wonder',\n",
              " 'vs',\n",
              " 'virgin',\n",
              " 'vehicle',\n",
              " 'turn',\n",
              " 'try',\n",
              " 'toddler',\n",
              " 'thursday',\n",
              " 'thousands',\n",
              " 'though',\n",
              " 'temple',\n",
              " 'sounds',\n",
              " 'sorry',\n",
              " 'refugio',\n",
              " 'radio',\n",
              " 'public',\n",
              " 'pradesh',\n",
              " 'moment',\n",
              " 'madhya',\n",
              " 'mad',\n",
              " 'link',\n",
              " 'knock',\n",
              " 'ignition',\n",
              " 'heavy',\n",
              " 'haha',\n",
              " 'guy',\n",
              " 'favorite',\n",
              " 'experts',\n",
              " 'else',\n",
              " 'downtown',\n",
              " 'download',\n",
              " 'declaration',\n",
              " 'couple',\n",
              " 'costlier',\n",
              " 'coaches',\n",
              " 'cnn',\n",
              " 'christian',\n",
              " 'chance',\n",
              " 'camp',\n",
              " 'cake',\n",
              " 'british',\n",
              " 'banned',\n",
              " 'anthrax',\n",
              " '25',\n",
              " '10',\n",
              " 'york',\n",
              " 'working',\n",
              " 'wanted',\n",
              " 'true',\n",
              " 'thinking',\n",
              " 'talk',\n",
              " 'sign',\n",
              " 'seeing',\n",
              " 'scared',\n",
              " 'russia',\n",
              " 'running',\n",
              " 'room',\n",
              " 'ready',\n",
              " 'r',\n",
              " 'property',\n",
              " 'patience',\n",
              " 'parole',\n",
              " 'park',\n",
              " 'outrage',\n",
              " 'nagasaki',\n",
              " 'myanmar',\n",
              " 'muslims',\n",
              " 'mount',\n",
              " 'mop',\n",
              " 'mishaps',\n",
              " 'middle',\n",
              " 'meek',\n",
              " 'large',\n",
              " 'isnt',\n",
              " 'instead',\n",
              " 'holding',\n",
              " 'gt',\n",
              " 'front',\n",
              " 'france',\n",
              " 'four',\n",
              " 'former',\n",
              " 'following',\n",
              " 'follow',\n",
              " 'film',\n",
              " 'fast',\n",
              " 'eye',\n",
              " 'entire',\n",
              " 'ebola',\n",
              " 'driver',\n",
              " 'computers',\n",
              " 'blue',\n",
              " 'blizzard',\n",
              " 'biggest',\n",
              " 'bed',\n",
              " 'beach',\n",
              " 'arsonist',\n",
              " 'ancient',\n",
              " 'action',\n",
              " 'yours',\n",
              " 'young',\n",
              " 'worse',\n",
              " 'upon',\n",
              " 'unconfirmed',\n",
              " 'tweet',\n",
              " 'taking',\n",
              " 'star',\n",
              " 'shots',\n",
              " 'sea',\n",
              " 'scene',\n",
              " 'rock',\n",
              " 'reports',\n",
              " 'reddits',\n",
              " 'quiz',\n",
              " 'pray',\n",
              " 'playing',\n",
              " 'nws',\n",
              " 'niggas',\n",
              " 'neighbours',\n",
              " 'miss',\n",
              " 'marks',\n",
              " 'libya',\n",
              " 'led',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "words_in_vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ppcqk-aZJIqo",
        "outputId": "cbbab09b-f9c5-44ab-854f-5ef2a669f11a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Wp42Mt5Lv6b",
        "outputId": "0dd1542a-080c-48a7-b9fa-033d11e56b60"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.02837469, -0.01519338,  0.04162248, ..., -0.00143163,\n",
              "         0.02782711,  0.00836086],\n",
              "       [ 0.02207127,  0.04276019, -0.04386932, ...,  0.01196408,\n",
              "        -0.03603273, -0.02402976],\n",
              "       [ 0.02875469,  0.05299776,  0.00231153, ..., -0.06808893,\n",
              "        -0.02926953, -0.02765083],\n",
              "       ...,\n",
              "       [ 0.03670838,  0.06035487,  0.09175117, ..., -0.02117459,\n",
              "         0.09314072,  0.00540106],\n",
              "       [-0.0074181 ,  0.02493073, -0.01782993, ...,  0.04147354,\n",
              "         0.00888075, -0.00230145],\n",
              "       [ 0.08095538, -0.01169421,  0.03783584, ..., -0.0835985 ,\n",
              "         0.01084063,  0.05440326]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "#getting the weight matrix of embedding layer\n",
        "#these are the numerical representations of each token in our training data which have been learnt for 5 epochs\n",
        "embed_weights = model_1.get_layer(\"embedding\").get_weights()[0]\n",
        "embed_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpQoGXDnWJoB",
        "outputId": "a39fc7ef-2b3f-4d5c-fdf9-d327934b7004"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 128)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "embed_weights.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZ8dBDaIbNdv"
      },
      "source": [
        "#Recurrent Neural Networks (RNN's)\n",
        "\n",
        "The premise of an RNN is simple: use information from the past to help you with the future (this is where the term recurrent comes from). In other words, take an input (X) and compute an output (y) based on all previous inputs.\n",
        "\n",
        "This concept is especially helpful when dealing with sequences such as passages of natural language text (such as our Tweets).\n",
        "\n",
        "Variants in the RNN:\n",
        "\n",
        "1. Long short term memory cells (LSTMs)\n",
        "\n",
        "2. Gated Recurrent Units(GRUs)\n",
        "\n",
        "3. Bidirectional RNN's(passes forward and backward along a sequence, left to right and right to left)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3y1hDVV4clYB"
      },
      "source": [
        "#Model_2: LSTM\n",
        "\n",
        "we're going to add an LSTM layer between our embedding and output.\n",
        "\n",
        "Input(text)->Tokenize->Embedding->Layers(RNNs/Dense)->Output(label probability)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "B21HceMiWOIV"
      },
      "outputs": [],
      "source": [
        "#creating an LSTM model\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "#print(x.shape)\n",
        "#x = layers.LSTM(units = 64, return_sequences = True)(x)  \n",
        "#when we are stacking RNN cells together, we need to set return_sequences = True\n",
        "#print(x.shape)\n",
        "x = layers.LSTM(64)(x)\n",
        "#print(x.shape)\n",
        "#x = layers.Dense(64, activation = \"relu\")(x)\n",
        "#print(x.shape)\n",
        "outputs = layers.Dense(1, activation = \"sigmoid\")(x)\n",
        "model_2 = tf.keras.Model(inputs, outputs, name = \"model_2_LSTM\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6B03fc5Ikher",
        "outputId": "493700b0-d9e9-446c-f41c-7c739158f9b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                49408     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,329,473\n",
            "Trainable params: 1,329,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#getting the summary\n",
        "model_2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "t7NJzVD6IQlc"
      },
      "outputs": [],
      "source": [
        "#compiling the model\n",
        "model_2.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = [\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSSl-GvkTYqP",
        "outputId": "3ff914bb-0c1e-4609-f8ae-f7889ff4a8fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_2_LSTM/20221219-173530\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 7s 9ms/step - loss: 0.2201 - accuracy: 0.9187 - val_loss: 0.5325 - val_accuracy: 0.8084\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.1552 - accuracy: 0.9423 - val_loss: 0.6874 - val_accuracy: 0.8018\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.1259 - accuracy: 0.9548 - val_loss: 0.7540 - val_accuracy: 0.7900\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 1s 7ms/step - loss: 0.1024 - accuracy: 0.9613 - val_loss: 0.8059 - val_accuracy: 0.7822\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 1s 7ms/step - loss: 0.0844 - accuracy: 0.9691 - val_loss: 0.9242 - val_accuracy: 0.7900\n"
          ]
        }
      ],
      "source": [
        "#fitting the model\n",
        "model_2_history = model_2.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data = (val_sentences, val_labels),\n",
        "                              callbacks = [create_tensorboard_callback(SAVE_DIR, \"model_2_LSTM\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agOMIeDgTxfV",
        "outputId": "ae9eeea0-4ed8-424b-ad56-1cee88b7a4c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.99956727e-01],\n",
              "       [1.08074516e-01],\n",
              "       [9.49622830e-04],\n",
              "       [9.85486269e-01],\n",
              "       [2.69126118e-04],\n",
              "       [3.30865830e-02],\n",
              "       [9.99317050e-01],\n",
              "       [6.84477249e-03],\n",
              "       [9.27401006e-01],\n",
              "       [8.71540792e-03]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "#making predictions with LSTM model\n",
        "model_2_pred_probs = model_2.predict(val_sentences)\n",
        "model_2_pred_probs[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "TynleGhEUGld"
      },
      "outputs": [],
      "source": [
        "#converting model_2 pred probs to labels\n",
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCSTitUuUWtn",
        "outputId": "20a596ac-a272-4248-fec6-49b5c3ec20d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 0., 0., 1., 0., 0., 1., 0., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "model_2_preds[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHCjrz08Uadw",
        "outputId": "3e3bef13-31d5-495a-9c15-88e7b59834b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 1, 0, 0, 0, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "val_labels[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p39Nw3gaUdDg",
        "outputId": "5a9f2c2d-4ac3-4e34-f57b-8f321394eba1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.00262467191601,\n",
              " 'precision': 0.7892578629331097,\n",
              " 'recall': 0.7900262467191601,\n",
              " 'f1': 0.7893704133490197}"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "#calculating the results\n",
        "model_2_results= calculate_results(y_true = val_labels,\n",
        "                                   y_pred = model_2_preds)\n",
        "model_2_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIX5EO92Utq3",
        "outputId": "e239133a-37fc-4820-c750-dce2beb77eb2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 83.33333333333334,\n",
              " 'precision': 0.8412202657738648,\n",
              " 'recall': 0.8333333333333334,\n",
              " 'f1': 0.8293755882702342}"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "baseline_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loqFPY42W930"
      },
      "source": [
        "#Model:3 LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "3FXYS1yIUvST"
      },
      "outputs": [],
      "source": [
        "#creating an GRU model\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.GRU(64)(x)\n",
        "#print(x.shape)\n",
        "#x = layers.Dense(64, activation = \"relu\")(x)\n",
        "#print(x.shape)\n",
        "outputs = layers.Dense(1, activation = \"sigmoid\")(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs, name = \"model_3_GRU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwXdzYDwDEC-",
        "outputId": "dc693ce8-92d2-4b49-dabf-f2c7cd8336f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3_GRU\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 64)                37248     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,317,313\n",
            "Trainable params: 1,317,313\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_3.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "kDErSsIKDTXS"
      },
      "outputs": [],
      "source": [
        "#compiling the model\n",
        "model_3.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = [\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnc1GETNFgIN",
        "outputId": "b2b81022-9627-436d-e879-9beab1f95a72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_3_LSTM/20221219-173543\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 4s 8ms/step - loss: 0.1591 - accuracy: 0.9390 - val_loss: 0.7162 - val_accuracy: 0.7900\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.0843 - accuracy: 0.9692 - val_loss: 0.8200 - val_accuracy: 0.7598\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.0718 - accuracy: 0.9723 - val_loss: 0.8746 - val_accuracy: 0.7795\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.0620 - accuracy: 0.9745 - val_loss: 1.1034 - val_accuracy: 0.7822\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.0528 - accuracy: 0.9765 - val_loss: 1.0987 - val_accuracy: 0.7585\n"
          ]
        }
      ],
      "source": [
        "#fitting the model\n",
        "model_3_history = model_3.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data = (val_sentences, val_labels),\n",
        "                              callbacks = [create_tensorboard_callback(SAVE_DIR, \"model_3_LSTM\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpF7EoGmE8CK",
        "outputId": "80e19852-10b7-4000-a77b-1f8002fb5d03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.9993420e-01],\n",
              "       [1.7559999e-01],\n",
              "       [1.0805309e-03],\n",
              "       [9.7708124e-01],\n",
              "       [1.2945270e-04],\n",
              "       [1.8424470e-03],\n",
              "       [9.9913728e-01],\n",
              "       [4.6146265e-03],\n",
              "       [9.9358022e-01],\n",
              "       [6.8304734e-03]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "#making predictions with GRU model\n",
        "model_3_pred_probs = model_3.predict(val_sentences)\n",
        "model_3_pred_probs[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "myhsmvcuFDds"
      },
      "outputs": [],
      "source": [
        "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sY_YzPL4EE9C",
        "outputId": "ecc547e9-28d7-45c9-a43e-2b9136bc7a0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.8530183727034,\n",
              " 'precision': 0.7621787544196879,\n",
              " 'recall': 0.7585301837270341,\n",
              " 'f1': 0.7594720561961684}"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "#calculating the results\n",
        "model_3_results= calculate_results(y_true = val_labels,\n",
        "                                   y_pred = model_3_preds)\n",
        "model_3_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBTWtCbCEO0E",
        "outputId": "829cb295-0200-4c44-dd38-08481cb5a17a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 83.33333333333334,\n",
              " 'precision': 0.8412202657738648,\n",
              " 'recall': 0.8333333333333334,\n",
              " 'f1': 0.8293755882702342}"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "baseline_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kg6zNIlwHtuK"
      },
      "source": [
        "#Model 4: Bidirectonal RNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "DVWG9cqmHn3f"
      },
      "outputs": [],
      "source": [
        "#creating an Bidirectional model\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "#x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
        "#print(x.shape)\n",
        "outputs = layers.Dense(1, activation = \"sigmoid\")(x)\n",
        "model_4 = tf.keras.Model(inputs, outputs, name = \"model_4_Bidirectional\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-gRLu2kPktB",
        "outputId": "5dc33f68-528e-4806-f9ba-e8e94ff15e55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4_Bidirectional\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 128)              98816     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,378,945\n",
            "Trainable params: 1,378,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#getting the summary\n",
        "model_4.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "i0h43t4LPqk6"
      },
      "outputs": [],
      "source": [
        "#compiling the model\n",
        "model_4.compile(loss = \"binary_crossentropy\",\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = [\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ThGB2M4QXa0",
        "outputId": "6775bbc0-2170-4061-931d-944c4c8472c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_4_LSTM/20221219-173553\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 6s 12ms/step - loss: 0.1101 - accuracy: 0.9666 - val_loss: 1.0083 - val_accuracy: 0.7769\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.0577 - accuracy: 0.9756 - val_loss: 1.1736 - val_accuracy: 0.7730\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.0466 - accuracy: 0.9793 - val_loss: 1.3016 - val_accuracy: 0.7612\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.0431 - accuracy: 0.9791 - val_loss: 1.3293 - val_accuracy: 0.7703\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.0427 - accuracy: 0.9806 - val_loss: 1.4241 - val_accuracy: 0.7520\n"
          ]
        }
      ],
      "source": [
        "#fitting the model\n",
        "model_4_history = model_4.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs = 5,\n",
        "                              validation_data = (val_sentences, val_labels),\n",
        "                              callbacks = [create_tensorboard_callback(SAVE_DIR, \"model_4_LSTM\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LGNJ7kdQ5y_",
        "outputId": "e3fa55db-9d5b-499b-bf70-85923d636bd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 4ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.99979973e-01],\n",
              "       [1.01394136e-03],\n",
              "       [1.83537137e-04],\n",
              "       [9.95271623e-01],\n",
              "       [1.20846935e-05],\n",
              "       [1.32492278e-03],\n",
              "       [9.99888659e-01],\n",
              "       [7.12386623e-04],\n",
              "       [9.94646847e-01],\n",
              "       [2.49995873e-03]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "#making predictions with bidirectional model\n",
        "model_4_pred_probs = model_4.predict(val_sentences)\n",
        "model_4_pred_probs[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "4zF0vqTyRB1b"
      },
      "outputs": [],
      "source": [
        "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ar5Gd9jKRIiz",
        "outputId": "0f18471d-4008-45b4-92f1-65c5698609e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.19685039370079,\n",
              " 'precision': 0.7558398222672278,\n",
              " 'recall': 0.7519685039370079,\n",
              " 'f1': 0.7529612026153994}"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "#calculating the results\n",
        "model_4_results= calculate_results(y_true = val_labels,\n",
        "                                   y_pred = model_4_preds)\n",
        "model_4_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FN0rLLZROGO",
        "outputId": "757bb839-2ade-4461-85c2-5918edb38cee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.8530183727034,\n",
              " 'precision': 0.7621787544196879,\n",
              " 'recall': 0.7585301837270341,\n",
              " 'f1': 0.7594720561961684}"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "model_3_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-6WnfSGUN4r"
      },
      "source": [
        "Bidirectional-LSTM is giving bad results than GRU model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PShnD_KxVMwr"
      },
      "source": [
        "#Model_5: CNN 1D for text and other types of sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVD6QWSTUMN2",
        "outputId": "da6099ee-f447-4dc9-8484-ed319cc7ed37"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 15, 128]), TensorShape([1, 15, 32]), TensorShape([1, 32]))"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "# Testing out the embedding, 1D convolutional and max pooling\n",
        "embedding_test = embedding(text_vectorizer([\"this is a test sentence\"])) # turn target sentence into embedding\n",
        "conv_1d = layers.Conv1D(filters=32, kernel_size=5,#looking at 5 words at a time\n",
        "                        strides=1, #default, skipping the first word and continuing with the rest\n",
        "                        activation = \"relu\",\n",
        "                        padding = \"same\") #output will be same as the inputactivation=\"relu\") # convolve over target sequence 5 words at a time\n",
        "conv_1d_output = conv_1d(embedding_test) # pass embedding through 1D convolutional layer\n",
        "max_pool = layers.GlobalMaxPool1D() \n",
        "max_pool_output = max_pool(conv_1d_output) # getting the most important features\n",
        "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHQLZGMcZxDw",
        "outputId": "21b5da95-4af7-4d69-8031-046688367d57"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[ 0.03428603,  0.03122544,  0.00461079, ...,  0.06617481,\n",
              "          0.02217629,  0.02016152],\n",
              "        [-0.01445302,  0.00654703,  0.0290289 , ...,  0.01219433,\n",
              "         -0.03243048,  0.00844325],\n",
              "        [ 0.05006618, -0.0288115 ,  0.04041455, ..., -0.02723657,\n",
              "          0.02632597, -0.03765038],\n",
              "        ...,\n",
              "        [ 0.02112085,  0.01457396, -0.00108965, ...,  0.02662428,\n",
              "          0.01034607, -0.00167463],\n",
              "        [ 0.02112085,  0.01457396, -0.00108965, ...,  0.02662428,\n",
              "          0.01034607, -0.00167463],\n",
              "        [ 0.02112085,  0.01457396, -0.00108965, ...,  0.02662428,\n",
              "          0.01034607, -0.00167463]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "embedding_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dKD5gZkb8iR",
        "outputId": "715d472f-2747-45af-8ebd-971328461ffc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 32), dtype=float32, numpy=\n",
              "array([[[0.09142403, 0.        , 0.02152052, 0.00766246, 0.        ,\n",
              "         0.        , 0.02729173, 0.03118492, 0.03338341, 0.        ,\n",
              "         0.03032018, 0.01149432, 0.        , 0.01202205, 0.01125849,\n",
              "         0.        , 0.        , 0.        , 0.010528  , 0.04119675,\n",
              "         0.        , 0.        , 0.03269086, 0.        , 0.        ,\n",
              "         0.00867069, 0.        , 0.        , 0.00108483, 0.        ,\n",
              "         0.04265711, 0.        ],\n",
              "        [0.01880841, 0.        , 0.01388094, 0.        , 0.02720241,\n",
              "         0.05431462, 0.        , 0.        , 0.02453585, 0.        ,\n",
              "         0.13153863, 0.        , 0.01440298, 0.        , 0.        ,\n",
              "         0.00507583, 0.01422143, 0.03268483, 0.        , 0.        ,\n",
              "         0.05007984, 0.        , 0.        , 0.04098433, 0.        ,\n",
              "         0.        , 0.        , 0.02527506, 0.        , 0.        ,\n",
              "         0.01682978, 0.02569659],\n",
              "        [0.01424623, 0.0450446 , 0.        , 0.        , 0.00659402,\n",
              "         0.        , 0.        , 0.        , 0.08010772, 0.08860241,\n",
              "         0.        , 0.01783672, 0.        , 0.        , 0.06304954,\n",
              "         0.02174526, 0.        , 0.        , 0.03339139, 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.04219884, 0.        , 0.        ,\n",
              "         0.02094185, 0.        ],\n",
              "        [0.        , 0.03494529, 0.        , 0.03969131, 0.        ,\n",
              "         0.05453724, 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.05249197, 0.05912453, 0.        , 0.        , 0.        ,\n",
              "         0.0178118 , 0.0328069 , 0.02240436, 0.00417021, 0.        ,\n",
              "         0.02946972, 0.        , 0.        , 0.        , 0.01642135,\n",
              "         0.01277559, 0.037034  , 0.03158531, 0.02554731, 0.        ,\n",
              "         0.07820354, 0.        ],\n",
              "        [0.01755161, 0.        , 0.00318575, 0.05004157, 0.        ,\n",
              "         0.00417046, 0.05713313, 0.        , 0.04125644, 0.        ,\n",
              "         0.04845206, 0.01084926, 0.0286217 , 0.03673242, 0.02136194,\n",
              "         0.        , 0.01511488, 0.        , 0.04136745, 0.        ,\n",
              "         0.        , 0.        , 0.06371805, 0.        , 0.08701962,\n",
              "         0.00924542, 0.        , 0.00506403, 0.09036068, 0.        ,\n",
              "         0.        , 0.        ],\n",
              "        [0.01334028, 0.        , 0.07933389, 0.        , 0.        ,\n",
              "         0.03735528, 0.        , 0.        , 0.        , 0.01188783,\n",
              "         0.04356051, 0.00473648, 0.        , 0.04049507, 0.0274253 ,\n",
              "         0.00763614, 0.04523861, 0.        , 0.04889596, 0.        ,\n",
              "         0.00164969, 0.        , 0.07585513, 0.05369338, 0.08384971,\n",
              "         0.        , 0.05027603, 0.        , 0.0663847 , 0.        ,\n",
              "         0.03295177, 0.        ],\n",
              "        [0.02373778, 0.        , 0.02232032, 0.01285336, 0.        ,\n",
              "         0.00234056, 0.        , 0.        , 0.02648262, 0.        ,\n",
              "         0.0075373 , 0.00756033, 0.        , 0.06216367, 0.        ,\n",
              "         0.        , 0.04875235, 0.01180617, 0.0093152 , 0.        ,\n",
              "         0.01191673, 0.        , 0.06494128, 0.02406146, 0.00499932,\n",
              "         0.        , 0.011834  , 0.00052964, 0.07011618, 0.        ,\n",
              "         0.        , 0.        ],\n",
              "        [0.03528976, 0.        , 0.02262251, 0.01470638, 0.        ,\n",
              "         0.0122015 , 0.        , 0.        , 0.01237233, 0.        ,\n",
              "         0.00699743, 0.00298028, 0.01604474, 0.01845931, 0.        ,\n",
              "         0.        , 0.00975911, 0.        , 0.03080383, 0.        ,\n",
              "         0.02638896, 0.        , 0.01597231, 0.        , 0.02315793,\n",
              "         0.        , 0.04327109, 0.01025609, 0.04988806, 0.        ,\n",
              "         0.        , 0.        ],\n",
              "        [0.03528976, 0.        , 0.02262252, 0.01470638, 0.        ,\n",
              "         0.0122015 , 0.        , 0.        , 0.01237234, 0.        ,\n",
              "         0.00699743, 0.00298028, 0.01604474, 0.01845931, 0.        ,\n",
              "         0.        , 0.00975911, 0.        , 0.03080383, 0.        ,\n",
              "         0.02638897, 0.        , 0.0159723 , 0.        , 0.02315792,\n",
              "         0.        , 0.04327109, 0.01025609, 0.04988805, 0.        ,\n",
              "         0.        , 0.        ],\n",
              "        [0.03528976, 0.        , 0.02262252, 0.01470638, 0.        ,\n",
              "         0.0122015 , 0.        , 0.        , 0.01237235, 0.        ,\n",
              "         0.00699743, 0.00298027, 0.01604475, 0.01845932, 0.        ,\n",
              "         0.        , 0.00975911, 0.        , 0.03080383, 0.        ,\n",
              "         0.02638897, 0.        , 0.01597231, 0.        , 0.02315791,\n",
              "         0.        , 0.04327109, 0.01025609, 0.04988806, 0.        ,\n",
              "         0.        , 0.        ],\n",
              "        [0.03528976, 0.        , 0.02262251, 0.01470638, 0.        ,\n",
              "         0.0122015 , 0.        , 0.        , 0.01237235, 0.        ,\n",
              "         0.00699742, 0.00298028, 0.01604474, 0.01845931, 0.        ,\n",
              "         0.        , 0.00975911, 0.        , 0.03080383, 0.        ,\n",
              "         0.02638896, 0.        , 0.01597231, 0.        , 0.02315791,\n",
              "         0.        , 0.04327109, 0.0102561 , 0.04988805, 0.        ,\n",
              "         0.        , 0.        ],\n",
              "        [0.03528975, 0.        , 0.02262251, 0.01470638, 0.        ,\n",
              "         0.0122015 , 0.        , 0.        , 0.01237233, 0.        ,\n",
              "         0.00699743, 0.00298028, 0.01604475, 0.01845931, 0.        ,\n",
              "         0.        , 0.0097591 , 0.        , 0.03080383, 0.        ,\n",
              "         0.02638896, 0.        , 0.0159723 , 0.        , 0.02315791,\n",
              "         0.        , 0.04327108, 0.0102561 , 0.04988805, 0.        ,\n",
              "         0.        , 0.        ],\n",
              "        [0.03528976, 0.        , 0.02262251, 0.01470637, 0.        ,\n",
              "         0.0122015 , 0.        , 0.        , 0.01237234, 0.        ,\n",
              "         0.00699742, 0.00298028, 0.01604475, 0.01845931, 0.        ,\n",
              "         0.        , 0.00975911, 0.        , 0.03080383, 0.        ,\n",
              "         0.02638896, 0.        , 0.01597231, 0.        , 0.02315792,\n",
              "         0.        , 0.04327109, 0.01025609, 0.04988806, 0.        ,\n",
              "         0.        , 0.        ],\n",
              "        [0.03752226, 0.        , 0.01456541, 0.01577228, 0.        ,\n",
              "         0.00839404, 0.        , 0.        , 0.02733103, 0.        ,\n",
              "         0.01512238, 0.00048638, 0.02421757, 0.01559652, 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.0157359 , 0.        ,\n",
              "         0.01178344, 0.        , 0.00175491, 0.        , 0.        ,\n",
              "         0.00229683, 0.01710614, 0.02237727, 0.02814615, 0.        ,\n",
              "         0.        , 0.        ],\n",
              "        [0.02893167, 0.        , 0.        , 0.01769468, 0.01259528,\n",
              "         0.00728377, 0.        , 0.00020525, 0.01299455, 0.        ,\n",
              "         0.0146939 , 0.        , 0.01992046, 0.00202124, 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.00603746, 0.        ,\n",
              "         0.00273509, 0.00773486, 0.00079135, 0.00196998, 0.        ,\n",
              "         0.00392165, 0.01357071, 0.03719061, 0.02109949, 0.        ,\n",
              "         0.        , 0.        ]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "conv_1d_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUSI-5t6cCjt",
        "outputId": "6b802cf7-d6d2-4836-fa8a-243344162033"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 32), dtype=float32, numpy=\n",
              "array([[0.09142403, 0.0450446 , 0.07933389, 0.05004157, 0.02720241,\n",
              "        0.05453724, 0.05713313, 0.03118492, 0.08010772, 0.08860241,\n",
              "        0.13153863, 0.05912453, 0.0286217 , 0.06216367, 0.06304954,\n",
              "        0.02174526, 0.04875235, 0.03268483, 0.04889596, 0.04119675,\n",
              "        0.05007984, 0.00773486, 0.07585513, 0.05369338, 0.08701962,\n",
              "        0.01277559, 0.05027603, 0.04219884, 0.09036068, 0.        ,\n",
              "        0.07820354, 0.02569659]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "max_pool_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSNpITbock9L",
        "outputId": "0f463241-1003-462b-c140-ee7206a0c836"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5_Conv1D\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 11, 64)            41024     \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Glo  (None, 64)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,321,089\n",
            "Trainable params: 1,321,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#building the CNN1D model\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape =(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.Conv1D(filters = 64, kernel_size = 5, strides = 1, activation = \"relu\", padding = \"valid\")(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_Conv1D\")\n",
        "\n",
        "# Compile Conv1D model\n",
        "model_5.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Get a summary of our 1D convolution model\n",
        "model_5.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEpppGH3sz4V",
        "outputId": "27be50ff-f166-424e-c0fd-b70b29d2d43b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/Conv1D/20221219-173621\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 3s 7ms/step - loss: 0.1189 - accuracy: 0.9651 - val_loss: 0.9653 - val_accuracy: 0.7677\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 1s 5ms/step - loss: 0.0753 - accuracy: 0.9710 - val_loss: 1.1058 - val_accuracy: 0.7638\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 1s 5ms/step - loss: 0.0626 - accuracy: 0.9750 - val_loss: 1.2271 - val_accuracy: 0.7507\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 1s 5ms/step - loss: 0.0547 - accuracy: 0.9781 - val_loss: 1.3046 - val_accuracy: 0.7585\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 1s 5ms/step - loss: 0.0522 - accuracy: 0.9775 - val_loss: 1.3146 - val_accuracy: 0.7362\n"
          ]
        }
      ],
      "source": [
        "#fittting our 1D CNN model to our text data.\n",
        "\n",
        "model_5_history = model_5.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs = 5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \n",
        "                                                                     \"Conv1D\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gepqKpW1aAV8",
        "outputId": "96ecf4ba-4c1a-4e46-bf4e-d65b95954453"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.0000000e+00],\n",
              "       [1.4443927e-02],\n",
              "       [2.7268012e-03],\n",
              "       [4.3184945e-01],\n",
              "       [7.7700264e-08],\n",
              "       [1.1017074e-04],\n",
              "       [9.9986303e-01],\n",
              "       [2.0655339e-04],\n",
              "       [9.0503377e-01],\n",
              "       [1.0449069e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "source": [
        "# Make predictions with model_5\n",
        "model_5_pred_probs = model_5.predict(val_sentences)\n",
        "model_5_pred_probs[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajppBSU2Ze5u",
        "outputId": "15c7be26-ef48-4f8a-ef75-3c73b036f0a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 0., 0., 0., 0., 0., 1., 0., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "# Convert model_5 prediction probabilities to labels\n",
        "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
        "model_5_preds[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjWuB8CUZ3q1",
        "outputId": "3b48efd5-ddc7-4b3a-9859-e4e13aad1a3f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 73.62204724409449,\n",
              " 'precision': 0.7378389883775414,\n",
              " 'recall': 0.7362204724409449,\n",
              " 'f1': 0.7368151793077514}"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "# Calculate model_5 evaluation metrics \n",
        "model_5_results = calculate_results(y_true=val_labels, \n",
        "                                    y_pred=model_5_preds)\n",
        "model_5_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sx_AzPD0aSeO",
        "outputId": "26a7dded-9fba-450d-f2af-25250732b06e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 83.33333333333334,\n",
              " 'precision': 0.8412202657738648,\n",
              " 'recall': 0.8333333333333334,\n",
              " 'f1': 0.8293755882702342}"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "baseline_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_rNjoY9fnbc"
      },
      "source": [
        "#Model_6:  TensorFlow Hub-Pretrained Sentence Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChfYZH2naWS5",
        "outputId": "07a745df-0d26-4f5a-d601-344de259ce36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[ 0.03131709  0.05056588  0.04521656  0.02834483  0.01331795  0.05679373\n",
            "  0.00666799  0.06959859 -0.01978569 -0.04904083  0.06660289  0.02081934\n",
            " -0.06427109 -0.00874941 -0.06268819  0.00671979 -0.02038973 -0.18132892\n",
            " -0.03427249  0.00836241 -0.00572656 -0.04895022  0.00313158 -0.01450487\n",
            "  0.03645915  0.05832612 -0.08921722  0.02370855  0.05378701  0.08655767\n",
            " -0.00829862 -0.06602843 -0.0471999  -0.03503707  0.03976117 -0.03169614\n",
            "  0.05754755 -0.01976361 -0.01643012 -0.03312145 -0.00466546  0.02529729\n",
            " -0.01356734  0.02915883  0.06647389 -0.02373346 -0.04707127  0.00129398\n",
            " -0.0478239  -0.08853508], shape=(50,), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow_hub as hub\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-large/5\")\n",
        "embed_samples = embed([sample_sentence,\n",
        "                       \"When you call the universal sentence encoder on a sentence, it turns it into numbers.\"])\n",
        "\n",
        "print(embed_samples[0][:50])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3CGHxou6aWwb",
        "outputId": "116b8807-cb03-4f0d-ded9-6a87fb8b0a75"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hi world! How are you? I hope that you are doing well.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "sample_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeU9VRMYrGYP",
        "outputId": "908653a2-41b6-4182-f9a7-e324c6828dc2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ],
      "source": [
        "embed_samples.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GE4_l4PvsgCK",
        "outputId": "a08767b1-e268-45f5-b0c2-4f054f7919bf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([512])"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ],
      "source": [
        "embed_samples[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "Jkq2agKssjNS"
      },
      "outputs": [],
      "source": [
        "#creating the keras layer using the USE pretrained layer from tensorflow hub\n",
        "sentence_encode_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder-large/5\",\n",
        "                                       input_shape=[], # shape of inputs coming to our model \n",
        "                                        dtype=tf.string, # data type of inputs coming to the USE layer\n",
        "                                        trainable=False, # keep the pretrained weights (we'll create a feature extractor)\n",
        "                                        name=\"USE\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07RHDVcGudVG",
        "outputId": "ff914a66-2d63-4386-8ccf-03cd6d20c894"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               147354880 \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 64)                32832     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 147,391,937\n",
            "Trainable params: 37,057\n",
            "Non-trainable params: 147,354,880\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Create model using the Sequential API\n",
        "model_6 = tf.keras.Sequential([\n",
        "  sentence_encode_layer, # take in sentences and then encode them into an embedding\n",
        "  layers.Dense(64, activation=\"relu\"),\n",
        "  layers.Dense(64, activation=\"relu\"),\n",
        "  layers.Dense(1, activation=\"sigmoid\")\n",
        "], name=\"model_6_USE\")\n",
        "\n",
        "# Compile model\n",
        "model_6.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "model_6.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3DjaYJJ0nvM",
        "outputId": "c1254c14-81bd-4168-f9f1-cfd7eb97b8dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder/20221219-173714\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 42s 70ms/step - loss: 0.4744 - accuracy: 0.7940 - val_loss: 0.4011 - val_accuracy: 0.8346\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 9s 44ms/step - loss: 0.3836 - accuracy: 0.8320 - val_loss: 0.4060 - val_accuracy: 0.8268\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 10s 48ms/step - loss: 0.3616 - accuracy: 0.8440 - val_loss: 0.4078 - val_accuracy: 0.8307\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 10s 48ms/step - loss: 0.3394 - accuracy: 0.8552 - val_loss: 0.4113 - val_accuracy: 0.8386\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 14s 65ms/step - loss: 0.3138 - accuracy: 0.8701 - val_loss: 0.4236 - val_accuracy: 0.8373\n"
          ]
        }
      ],
      "source": [
        "# Train a classifier on top of pretrained embeddings\n",
        "model_6_history = model_6.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \n",
        "                                                                     \"tf_hub_sentence_encoder\")])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3VKyltu09_M",
        "outputId": "97a3252d-de3a-4ee1-b48a-c944b4f45c16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 5s 42ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9965084 ],\n",
              "       [0.06514587],\n",
              "       [0.23729642],\n",
              "       [0.84910923],\n",
              "       [0.05720283],\n",
              "       [0.1993195 ],\n",
              "       [0.18402863],\n",
              "       [0.06785306],\n",
              "       [0.34288898],\n",
              "       [0.36396638]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "# Make predictions with USE TF Hub model\n",
        "model_6_pred_probs = model_6.predict(val_sentences)\n",
        "model_6_pred_probs[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xh9igH-W1CgE",
        "outputId": "914ec742-b155-4f71-cbca-a86c53439d93"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ],
      "source": [
        "# Convert prediction probabilities to labels\n",
        "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
        "model_6_preds[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAZ246gd1ECk",
        "outputId": "f02e1315-3a40-408a-f298-13df19560bbc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 83.72703412073491,\n",
              " 'precision': 0.8385584953155267,\n",
              " 'recall': 0.8372703412073491,\n",
              " 'f1': 0.8354957666020125}"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "source": [
        "# Calculate model 6 performance metrics\n",
        "model_6_results = calculate_results(val_labels, model_6_preds)\n",
        "model_6_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQmu2UK91FrD",
        "outputId": "967b11e3-fb20-4c8d-f7f1-331027ca53b2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 83.33333333333334,\n",
              " 'precision': 0.8412202657738648,\n",
              " 'recall': 0.8333333333333334,\n",
              " 'f1': 0.8293755882702342}"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ],
      "source": [
        "#comparing with the baseline model\n",
        "baseline_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVV8EDwg1cze"
      },
      "source": [
        "Model_6 almost tried to beat the baseline model with the layers increment...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxSAwFta3D5f"
      },
      "source": [
        "#Model_7: TF Hub pretrained USE but with 10% of training data\n",
        "\n",
        " we're going to make a small subset of the training data (10%), train a model and evaluate it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "p_b3AAqR1Mdi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "train_sentences_90_percent, train_sentences_10_percent, train_labels_90_percent, train_labels_10_percent = train_test_split(np.array(train_sentences),\n",
        "                                                                                                                            train_labels,\n",
        "                                                                                                                            test_size=0.1,\n",
        "                                                                                                                            random_state=22)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vY3Tkt3pQFq9",
        "outputId": "cea7b639-252d-4466-e122-cee672ef7710"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training examples: 6851\n",
            "Length of 10% training examples: 686\n"
          ]
        }
      ],
      "source": [
        "# Check length of 10 percent datasets\n",
        "print(f\"Total training examples: {len(train_sentences)}\")\n",
        "print(f\"Length of 10% training examples: {len(train_sentences_10_percent)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgufFGeBRRWt"
      },
      "source": [
        "To make sure we're making an appropriate comparison between our model's ability to learn from the full training set and 10% subset, we'll clone our USE model (model_6) using the tf.keras.models.clone_model() method.\n",
        "\n",
        "Doing this will create the same architecture but reset the learned weights of the clone target (pretrained weights from the USE will remain but all others will be reset)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBhkz4RaQFne",
        "outputId": "3eff3af5-721a-454f-aec8-b9cf9bb04b86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               147354880 \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 64)                32832     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 147,391,937\n",
            "Trainable params: 37,057\n",
            "Non-trainable params: 147,354,880\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#cloning model_6 but resetting the weights\n",
        "model_7 = tf.keras.models.clone_model(model_6)\n",
        "\n",
        "#compiling the model\n",
        "model_7.compile(loss = \"binary_crossentropy\",\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = [\"accuracy\"])\n",
        "\n",
        "#getting a summary same like the model_6\n",
        "model_7.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMMMlSlyQFk_",
        "outputId": "85ff33e4-86bc-49e7-d730-c05c0ef09517"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/10_percent_tf_hub_sentence_encoder/20221219-174025\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 34s 343ms/step - loss: 0.6798 - accuracy: 0.6545 - val_loss: 0.6552 - val_accuracy: 0.7835\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.6095 - accuracy: 0.8017 - val_loss: 0.5646 - val_accuracy: 0.7940\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.4854 - accuracy: 0.8222 - val_loss: 0.4673 - val_accuracy: 0.7966\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.3814 - accuracy: 0.8440 - val_loss: 0.4595 - val_accuracy: 0.7848\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.3112 - accuracy: 0.8746 - val_loss: 0.4706 - val_accuracy: 0.7913\n"
          ]
        }
      ],
      "source": [
        "# Fit the model to 10% of the training data\n",
        "model_7_history = model_7.fit(x=train_sentences_10_percent,\n",
        "                              y=train_labels_10_percent,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"10_percent_tf_hub_sentence_encoder\")])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcleTF6VQFih",
        "outputId": "719a9d5d-ee18-4086-fecd-f72dacb44622"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 6s 45ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.98958814],\n",
              "       [0.02700598],\n",
              "       [0.27343273],\n",
              "       [0.7676864 ],\n",
              "       [0.18390043],\n",
              "       [0.23875996],\n",
              "       [0.31475443],\n",
              "       [0.20263398],\n",
              "       [0.3083981 ],\n",
              "       [0.35285136]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ],
      "source": [
        "# Make predictions with the model trained on 10% of the data\n",
        "model_7_pred_probs = model_7.predict(val_sentences)\n",
        "model_7_pred_probs[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvd5XHhOQFff",
        "outputId": "24d6f741-7444-4c31-fcae-c6f098d2b383"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ],
      "source": [
        "# Convert prediction probabilities to labels\n",
        "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
        "model_7_preds[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0i0IlkTEQFT3",
        "outputId": "da8b15fc-ced3-44f6-fc54-804e8bd8c9d6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.13385826771653,\n",
              " 'precision': 0.7936140150821528,\n",
              " 'recall': 0.7913385826771654,\n",
              " 'f1': 0.7919831769907685}"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ],
      "source": [
        "# Calculate model results\n",
        "model_7_results = calculate_results(val_labels, model_7_preds)\n",
        "model_7_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqOAWYoyQFGg",
        "outputId": "8c63583f-a552-475a-be4b-30f7443d52a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 83.33333333333334,\n",
              " 'precision': 0.8412202657738648,\n",
              " 'recall': 0.8333333333333334,\n",
              " 'f1': 0.8293755882702342}"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ],
      "source": [
        "baseline_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YDpMOR6Squ4"
      },
      "source": [
        "#Comparing the performance of each of our models\n",
        "\n",
        "creating a pandas dataframe to view the results of each model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "jj6hXTTWSj7q",
        "outputId": "a7c05f70-ad5a-4d0e-fc75-4a064b960da6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          accuracy  precision    recall        f1\n",
              "baseline                 83.333333   0.841220  0.833333  0.829376\n",
              "simple_dense             82.283465   0.822645  0.822835  0.822727\n",
              "lstm                     79.002625   0.789258  0.790026  0.789370\n",
              "gru                      75.853018   0.762179  0.758530  0.759472\n",
              "bidirectional            75.196850   0.755840  0.751969  0.752961\n",
              "conv1d                   73.622047   0.737839  0.736220  0.736815\n",
              "tf_hub_sentence_encoder  83.727034   0.838558  0.837270  0.835496\n",
              "tf_hub_10_percent_data   79.133858   0.793614  0.791339  0.791983"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-48643ea2-4493-46bc-a95f-91accf65c25f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>baseline</th>\n",
              "      <td>83.333333</td>\n",
              "      <td>0.841220</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.829376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>simple_dense</th>\n",
              "      <td>82.283465</td>\n",
              "      <td>0.822645</td>\n",
              "      <td>0.822835</td>\n",
              "      <td>0.822727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lstm</th>\n",
              "      <td>79.002625</td>\n",
              "      <td>0.789258</td>\n",
              "      <td>0.790026</td>\n",
              "      <td>0.789370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gru</th>\n",
              "      <td>75.853018</td>\n",
              "      <td>0.762179</td>\n",
              "      <td>0.758530</td>\n",
              "      <td>0.759472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bidirectional</th>\n",
              "      <td>75.196850</td>\n",
              "      <td>0.755840</td>\n",
              "      <td>0.751969</td>\n",
              "      <td>0.752961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>conv1d</th>\n",
              "      <td>73.622047</td>\n",
              "      <td>0.737839</td>\n",
              "      <td>0.736220</td>\n",
              "      <td>0.736815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tf_hub_sentence_encoder</th>\n",
              "      <td>83.727034</td>\n",
              "      <td>0.838558</td>\n",
              "      <td>0.837270</td>\n",
              "      <td>0.835496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tf_hub_10_percent_data</th>\n",
              "      <td>79.133858</td>\n",
              "      <td>0.793614</td>\n",
              "      <td>0.791339</td>\n",
              "      <td>0.791983</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-48643ea2-4493-46bc-a95f-91accf65c25f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-48643ea2-4493-46bc-a95f-91accf65c25f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-48643ea2-4493-46bc-a95f-91accf65c25f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ],
      "source": [
        "models_results = pd.DataFrame({\"baseline\": baseline_results,\n",
        "                                  \"simple_dense\": model_1_results,\n",
        "                                  \"lstm\": model_2_results,\n",
        "                                  \"gru\": model_3_results,\n",
        "                                  \"bidirectional\": model_4_results,\n",
        "                                  \"conv1d\": model_5_results,\n",
        "                                  \"tf_hub_sentence_encoder\": model_6_results,\n",
        "                                  \"tf_hub_10_percent_data\": model_7_results})\n",
        "models_results = models_results.transpose()\n",
        "models_results"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Saving and loading a trained model\n",
        "\n",
        "Two main ways to save a model in TF:\n",
        "\n",
        "1. The HDF5 format.\n",
        "\n",
        "2. The SavedModel format (default)."
      ],
      "metadata": {
        "id": "914s46UhiViG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "rhMn1iTITZmJ"
      },
      "outputs": [],
      "source": [
        "#saving using HDF5 format\n",
        "model_6.save(\"model_6.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you save a model as a HDF5, when loading it back in, you need to let TensorFlow know about any custom objects you've used (e.g. components which aren't built from pure TensorFlow, such as TensorFlow Hub components)."
      ],
      "metadata": {
        "id": "7GAIdYr4i9ZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model with custom Hub Layer (required with HDF5 format)\n",
        "loaded_model_6 = tf.keras.models.load_model(\"model_6.h5\", \n",
        "                                            custom_objects={\"KerasLayer\": hub.KerasLayer})\n"
      ],
      "metadata": {
        "id": "bNZAhFe7iwVJ"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#looking at the way our loaded model performing:\n",
        "loaded_model_6.evaluate(val_sentences, val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9s1HDu1SjCg8",
        "outputId": "8a11dd7b-4f97-457a-fa97-5593cc9c4a23"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 6s 46ms/step - loss: 0.4236 - accuracy: 0.8373\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.42356076836586, 0.8372703194618225]"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.evaluate(val_sentences, val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gwz1t7plkCXU",
        "outputId": "51794183-0e8f-462c-bc4b-d13594ef402b"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 5ms/step - loss: 0.5641 - accuracy: 0.7900\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5641358494758606, 0.7900262475013733]"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calling the save() method on our target model and passing it a filepath allows us to save our model in the SavedModel format."
      ],
      "metadata": {
        "id": "q5tQJB8qlPm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#saving to the SavedModel format\n",
        "model_6.save(\"model_6_SavedModel_format\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXSEiV-AkQ6T",
        "outputId": "e788332c-4db4-4ae2-8203-1210307526ac"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) USE_input with unsupported characters which will be renamed to use_input in the SavedModel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you use SavedModel format (default), you can reload your model without specifying custom objects using the tensorflow.keras.models.load_model() function."
      ],
      "metadata": {
        "id": "IJHlpf5em_q3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load TF Hub Sentence Encoder SavedModel\n",
        "loaded_model_6_SavedModel = tf.keras.models.load_model(\"model_6_SavedModel_format\")\n"
      ],
      "metadata": {
        "id": "ZOXPYis1ldKT"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate loaded SavedModel format\n",
        "loaded_model_6_SavedModel.evaluate(val_sentences, val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OhaN4LTnGiL",
        "outputId": "9230dbd1-3532-4568-efb7-79322c5e6d6a"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 6s 46ms/step - loss: 0.4236 - accuracy: 0.8373\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4235606789588928, 0.8372703194618225]"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Either of the methods of saving and loading the models gives us the same result...\n",
        "\n",
        "But for most use cases, the SavedModel format will suffice. However, this is a TensorFlow specific standard. If you need a more general-purpose data standard, HDF5 might be better. "
      ],
      "metadata": {
        "id": "yozL5kh-nxsA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finding the most wrong examples\n",
        "\n",
        "One of the best ways to inspect your data is to sort your model's predictions and find the samples it got most wrong, meaning, what predictions had a high prediction probability but turned out to be wrong."
      ],
      "metadata": {
        "id": "o7_dTUPHntmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataframe with validation sentences and best performing model predictions\n",
        "val_df = pd.DataFrame({\"text\": val_sentences,\n",
        "                       \"target\": val_labels,\n",
        "                       \"pred\": model_6_preds,\n",
        "                       \"pred_prob\": tf.squeeze(model_6_pred_probs)})\n",
        "val_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Hu-CMzcqnMUn",
        "outputId": "9e8cfed5-c8ea-4a85-dce3-843b602f6b93"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  target  pred  pred_prob\n",
              "0  Three-alarm fire destroys two residential buil...       1   1.0   0.996508\n",
              "1  Do you feel engulfed with low self-image? Take...       0   0.0   0.065146\n",
              "2  James Kunstler: How bad architecture wrecked c...       0   0.0   0.237296\n",
              "3  natural disaster ÛÒ News Stories About natura...       1   1.0   0.849109\n",
              "4  New Explosion-proof Tempered Glass Screen Prot...       0   0.0   0.057203"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f719604c-4453-4367-9bc0-ca5357100e50\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Three-alarm fire destroys two residential buil...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.996508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Do you feel engulfed with low self-image? Take...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.065146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>James Kunstler: How bad architecture wrecked c...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.237296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>natural disaster ÛÒ News Stories About natura...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.849109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>New Explosion-proof Tempered Glass Screen Prot...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.057203</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f719604c-4453-4367-9bc0-ca5357100e50')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f719604c-4453-4367-9bc0-ca5357100e50 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f719604c-4453-4367-9bc0-ca5357100e50');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's find our model's wrong predictions (where target != pred) and sort them by their prediction probability (the pred_prob column)."
      ],
      "metadata": {
        "id": "v8rFpL_Xqp37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding the wrong predictions and sorting by prediction probabilities\n",
        "most_wrong = val_df[val_df[\"target\"] != val_df[\"pred\"]].sort_values(\"pred_prob\", ascending=False)\n",
        "most_wrong[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "doMyWYAzqS5f",
        "outputId": "47548369-5baa-4a70-d746-81ce10eff9ba"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  text  target  pred  \\\n",
              "136  Kosciusko police investigating pedestrian fata...       0   1.0   \n",
              "106  Mourning notices for stabbing arson victims st...       0   1.0   \n",
              "69   Google Alert: Emergency units simulate a chemi...       0   1.0   \n",
              "555  Former Township fire truck being used in Phili...       0   1.0   \n",
              "420  It's a deluge in Trois-Rivieres. About one hou...       0   1.0   \n",
              "757         LRT LOOK AT ALL MY TOM FEELS FLOODING BACK       0   1.0   \n",
              "463  RT @DianneG: Gunshot wound #9 is in the bicep....       0   1.0   \n",
              "230  Zimbabwe is a country with a collapsed governm...       0   1.0   \n",
              "345  Epilepsy claims another. Common and still a ch...       0   1.0   \n",
              "90   RAIN RAIN GO AWAY... A soaker is on the way \\n...       0   1.0   \n",
              "\n",
              "     pred_prob  \n",
              "136   0.998104  \n",
              "106   0.982159  \n",
              "69    0.976612  \n",
              "555   0.970742  \n",
              "420   0.959786  \n",
              "757   0.931062  \n",
              "463   0.912370  \n",
              "230   0.904149  \n",
              "345   0.902281  \n",
              "90    0.881174  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-144dc490-ed5a-477d-aa57-27ab43da4205\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>136</th>\n",
              "      <td>Kosciusko police investigating pedestrian fata...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.998104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>Mourning notices for stabbing arson victims st...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.982159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>Google Alert: Emergency units simulate a chemi...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.976612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>555</th>\n",
              "      <td>Former Township fire truck being used in Phili...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.970742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>420</th>\n",
              "      <td>It's a deluge in Trois-Rivieres. About one hou...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.959786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>757</th>\n",
              "      <td>LRT LOOK AT ALL MY TOM FEELS FLOODING BACK</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.931062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>463</th>\n",
              "      <td>RT @DianneG: Gunshot wound #9 is in the bicep....</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.912370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230</th>\n",
              "      <td>Zimbabwe is a country with a collapsed governm...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.904149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>345</th>\n",
              "      <td>Epilepsy claims another. Common and still a ch...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.902281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>RAIN RAIN GO AWAY... A soaker is on the way \\n...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.881174</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-144dc490-ed5a-477d-aa57-27ab43da4205')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-144dc490-ed5a-477d-aa57-27ab43da4205 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-144dc490-ed5a-477d-aa57-27ab43da4205');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can see the false positives from the sorted samples of most_wrong DataFrame."
      ],
      "metadata": {
        "id": "mA98uOl6rsdd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking for the false positives(predicting 1 instead of 0)\n",
        "\n",
        "for row in most_wrong[:10].itertuples(): # loop through the top 10 rows (change the index to view different rows)\n",
        "  _, text, target, pred, prob = row #leaving the index values taking the rest of the values\n",
        "  print(f\"Target: {target}, Pred: {int(pred)}, Prob: {prob}\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"----\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uqk6NyISrVuX",
        "outputId": "67653c5b-e0f0-4400-f886-4e4dfdc39ed3"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 0, Pred: 1, Prob: 0.9981037378311157\n",
            "Text:\n",
            "Kosciusko police investigating pedestrian fatality hit by a train Thursday http://t.co/m5djLLxoZP\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.9821586012840271\n",
            "Text:\n",
            "Mourning notices for stabbing arson victims stir Û÷politics of griefÛª in Israel: Posters for Shira Banki and A... http://t.co/3GZ5zQQTHe\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.9766117930412292\n",
            "Text:\n",
            "Google Alert: Emergency units simulate a chemical explosion at NU http://t.co/NDgpWYxu6H\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.9707418084144592\n",
            "Text:\n",
            "Former Township fire truck being used in Philippines - Langley Times http://t.co/iMiLsFxntf #filipino\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.9597859382629395\n",
            "Text:\n",
            "It's a deluge in Trois-Rivieres. About one hour to get to #legionstrackandfield http://t.co/PuE5xNZnQB\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.9310624003410339\n",
            "Text:\n",
            "LRT LOOK AT ALL MY TOM FEELS FLOODING BACK\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.9123696684837341\n",
            "Text:\n",
            "RT @DianneG: Gunshot wound #9 is in the bicep. only 1 of the 10 wounds that is not in the chest/torso area.  #KerrickTrial #JonathanFerrell\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.904149055480957\n",
            "Text:\n",
            "Zimbabwe is a country with a collapsed government ruled by a dictator while many live below the poverty line.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.9022807478904724\n",
            "Text:\n",
            "Epilepsy claims another. Common and still a challenge to treat. Superhero toddler with rare epilepsy (Dravet) drowns http://t.co/VBo1tjNdps\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.8811740875244141\n",
            "Text:\n",
            "RAIN RAIN GO AWAY... A soaker is on the way \n",
            "------&gt; http://t.co/jQFcY9GuqV &lt;----- http://t.co/tN65puhfhw\n",
            "\n",
            "----\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's view the  bottom end of our most_wrong DataFrame to inspect false negatives (model predicts 0, not a real diaster Tweet, when it should've predicted 1, real diaster Tweet)."
      ],
      "metadata": {
        "id": "Wnfrn567swol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the most wrong false negatives (model predicted 0 when should've predict 1)\n",
        "for row in most_wrong[-10:].itertuples():\n",
        "  _, text, target, pred, prob = row\n",
        "  print(f\"Target: {target}, Pred: {int(pred)}, Prob: {prob}\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"----\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2Ckv68_sZQy",
        "outputId": "0ab298ec-a8e9-4cbd-cd33-5f92321b5257"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 1, Pred: 0, Prob: 0.046132124960422516\n",
            "Text:\n",
            "Someone teaching you that obedience will obliterate trials in your life is trying to sell you a used car. Jesus's life blows that theory.'\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.043872032314538956\n",
            "Text:\n",
            "@BradleyBrad47 yeah but being fast and doing extremely high damage is what its all about if you want fast then im gonna have to get u the-\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.04301667585968971\n",
            "Text:\n",
            "Stemming from my #Cubs talk- the team rosters 2 cancer survivors in @ARizzo44 &amp; @JLester34...@Cubs fans: help another http://t.co/XGnjgLE9eQ\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.03915736451745033\n",
            "Text:\n",
            "#PBBan (Temporary:300) hyider_ghost2 @'aRmageddon | DO NOT KILL | FLAGS ONLY | Fast XP' for Reason\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.03680930286645889\n",
            "Text:\n",
            "@SaintRobinho86 someone has to be at the bottom of every league. Tonight clearly demonstrated why the Lions are where they are - sunk!\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.03014947660267353\n",
            "Text:\n",
            "Flattened thee striker\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.029411619529128075\n",
            "Text:\n",
            "@tiggr_ why only Squad Obliteration?\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.024219896644353867\n",
            "Text:\n",
            "Why did I come to work today.. Literally wanna collapse of exhaustion\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.01956832967698574\n",
            "Text:\n",
            "If you're in search of powerful content to improve your business or have been frustrated with the deluge of 'quantitÛ_https://t.co/64cyMG1lTG\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.018725775182247162\n",
            "Text:\n",
            "VICTORINOX SWISS ARMY DATE WOMEN'S RUBBER MOP WATCH 241487 http://t.co/yFy3nkkcoH http://t.co/KNEhVvOHVK\n",
            "\n",
            "----\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Making predictions on the test dataset\n",
        "test_sentences = test_df[\"text\"].to_list()\n",
        "test_samples = random.sample(test_sentences, 10)\n",
        "for test_sample in test_samples:\n",
        "  pred_prob = tf.squeeze(model_6.predict([test_sample])) # has to be list\n",
        "  pred = tf.round(pred_prob)\n",
        "  print(f\"Pred: {int(pred)}, Prob: {pred_prob}\")\n",
        "  print(f\"Text:\\n{test_sample}\\n\")\n",
        "  print(\"----\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfNdx1R9tCQ3",
        "outputId": "3dd9841a-5ef2-448c-94c9-b6ad4792722d"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 354ms/step\n",
            "Pred: 0, Prob: 0.13772046566009521\n",
            "Text:\n",
            "Seen on Fahlo:#WCW All Hail the QueenåÊ?? http://t.co/zrhXy9iBno http://t.co/Opjz8fGdIy\n",
            "\n",
            "----\n",
            "\n",
            "1/1 [==============================] - 0s 155ms/step\n",
            "Pred: 0, Prob: 0.18139323592185974\n",
            "Text:\n",
            "Not only did Drake kill Meek Mill but he started T bagging his his dead body ????????????\n",
            "\n",
            "----\n",
            "\n",
            "1/1 [==============================] - 0s 102ms/step\n",
            "Pred: 0, Prob: 0.06077865883708\n",
            "Text:\n",
            "Starting a GoFundMe page for a new set of rims since i demolished mine last night #helpabrotherout\n",
            "\n",
            "----\n",
            "\n",
            "1/1 [==============================] - 0s 169ms/step\n",
            "Pred: 0, Prob: 0.06060149148106575\n",
            "Text:\n",
            "chickmt123: #letsFootball #atk WIRED : Reddit will now quarantine offensive content http://t.co/wvn6GrIyPq (httpÛ_ http://t.co/pgIHchdURJ\n",
            "\n",
            "----\n",
            "\n",
            "1/1 [==============================] - 0s 138ms/step\n",
            "Pred: 0, Prob: 0.06051542982459068\n",
            "Text:\n",
            "Senators have another year to determine Hoffman's v... #ColoradoAvs #NHLAvalanche http://t.co/CIzZOc6f0D http://t.co/PEmYHD3Nfz\n",
            "\n",
            "----\n",
            "\n",
            "1/1 [==============================] - 0s 109ms/step\n",
            "Pred: 1, Prob: 0.9833983182907104\n",
            "Text:\n",
            "Watch This Airport Get Swallowed Up By A Sandstorm In Under A Minute http://t.co/nvSjHdGDGZ\n",
            "\n",
            "----\n",
            "\n",
            "1/1 [==============================] - 0s 298ms/step\n",
            "Pred: 0, Prob: 0.13039307296276093\n",
            "Text:\n",
            "[VID]150806 Luhan From Luhan Studio Channel on YOUKU Update \n",
            "\n",
            "http://t.co/W7yeZkQlCJ http://t.co/C0QWZ0IshR\n",
            "\n",
            "----\n",
            "\n",
            "1/1 [==============================] - 0s 107ms/step\n",
            "Pred: 1, Prob: 0.9949893355369568\n",
            "Text:\n",
            "VIDEO: Link to the billowing fire after the SouthTowne Lanes roof collapsed: http://t.co/YrRHqZLKoR http://t.co/dXk4sUXMKV\n",
            "\n",
            "----\n",
            "\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Pred: 0, Prob: 0.40999501943588257\n",
            "Text:\n",
            ".@CBCNorth see photo Old Lady of the Falls (sacred site) RR says derailed Talston power line to diamond mines in 2010\n",
            "http://t.co/SxlfSNsPH0\n",
            "\n",
            "----\n",
            "\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "Pred: 0, Prob: 0.12348929792642593\n",
            "Text:\n",
            "Why can't gay men donate blood? http://t.co/v2Etl8P9eQ http://t.co/NLnyzeljbw\n",
            "\n",
            "----\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The speed/score tradeoff\n",
        "\n",
        "The point here is to illustrate the best model you find through experimentation, might not be the model you end up using in production.\n",
        "\n",
        "To make this more concrete, let's write a function to take a model and a number of samples and time how long the given model takes to make predictions on those samples."
      ],
      "metadata": {
        "id": "uPJ_G8aiuN9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the time taken by predictions\n",
        "import time\n",
        "def pred_timer(model, samples):\n",
        "  \"\"\"\n",
        "  Times how long a model takes to make predictions on samples.\n",
        "  \n",
        "  Args:\n",
        "  ----\n",
        "  model = a trained model\n",
        "  sample = a list of samples\n",
        "\n",
        "  Returns:\n",
        "  ----\n",
        "  total_time = total elapsed time for model to make predictions on samples\n",
        "  time_per_pred = time in seconds per single sample\n",
        "  \"\"\"\n",
        "  start_time = time.perf_counter() # get start time\n",
        "  model.predict(samples) # make predictions\n",
        "  end_time = time.perf_counter() # get finish time\n",
        "  total_time = end_time-start_time # calculate how long predictions took to make\n",
        "  time_per_pred = total_time/len(val_sentences) # find prediction time per sample\n",
        "  return total_time, time_per_pred"
      ],
      "metadata": {
        "id": "_FYPnjLgtnIk"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's use our pred_timer() function to evaluate the prediction times of our best performing model (model_6) and our baseline model (model_0)."
      ],
      "metadata": {
        "id": "nrEEncv1xIGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating TF Hub Sentence Encoder prediction times\n",
        "model_6_total_pred_time, model_6_time_per_pred = pred_timer(model_6, val_sentences)\n",
        "model_6_total_pred_time, model_6_time_per_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mM7MtxqIxELi",
        "outputId": "c8866190-ff46-44d1-fd87-602c3544ab25"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 2s 80ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2.609680080999169, 0.0034247770091852614)"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating Naive Bayes prediction times\n",
        "baseline_total_pred_time, baseline_time_per_pred = pred_timer(model_0, val_sentences)\n",
        "baseline_total_pred_time, baseline_time_per_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5BvsLlExd8b",
        "outputId": "3f9a5cdb-98a8-4f7e-e4e2-4d95ebb25670"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.05050601899984031, 6.628086482918676e-05)"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems that our best performing model takes over more time to make predictions as our baseline model.\n",
        "\n",
        "Now lets compare the F1 score(combination of precision and recall, usually a good overall metric for a classification model) with time per prediction."
      ],
      "metadata": {
        "id": "8mTbglaAx9uo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.scatter(baseline_time_per_pred, baseline_results[\"f1\"], label=\"baseline\")\n",
        "plt.scatter(model_6_time_per_pred, model_6_results[\"f1\"], label=\"tf_hub_sentence_encoder\")\n",
        "plt.legend()\n",
        "plt.title(\"F1-score versus time per prediction\")\n",
        "plt.xlabel(\"Time per prediction\")\n",
        "plt.ylabel(\"F1-Score\");"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "8vAub2cixh4z",
        "outputId": "677e8780-38b5-4c06-ebe9-4731621e025e"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ideal position for each of these dots is to be in the top left of the plot (low time per prediction, high F1-score).\n",
        "\n",
        "In our case, there's a clear tradeoff for time per prediction and performance. Our best performing model takes an order of magnitude longer per prediction but only results in a few F1-score point increase.\n",
        "\n",
        "This kind of tradeoff is something we'll need to keep in mind when incorporating machine learning models into our own applications."
      ],
      "metadata": {
        "id": "vPxOWLHPzd6E"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RJBBwpNHzUwQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNo3DZh5mCjP6YIfRid6lYu",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}